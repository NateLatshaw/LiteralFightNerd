[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Welcome to LiteralFightNerd!",
    "section": "",
    "text": "This blog seeks to bring quantitative analysis to the combat sports world in a form that is approachable for non-technical audiences but still rigorous for those who are more quantitatively inclined.\nI am a Data Scientist currently living in the Philadelphia, PA area. I’ve always been passionate about both data and sports. I was a collegiate soccer player at Dickinson College before earning an M.S. in Statistics from Carnegie Mellon University. Now I spend my free time combining my passions to conduct quantitative analysis primarily on combat sports, like mixed martial arts (MMA).\nI’ve witnessed most major American sports go through some sort of analytics revolution, but I have not yet seen the same growth in MMA. Hence, I think there’s room to use publicly available MMA data in new ways that are beneficial to anyone interested in the sport, from fighters and coaches to MMA experts and sports bettors to even casual fans.\nI invite feedback on all of my work. While all of my current plans for this blog involve quantitative MMA analysis, I am interested in branching out to other sports analytics or data science topics in the future. I’m always open to connecting with others to collaborate or just exchange ideas. The best way to connect with me is through Twitter, and my Linktree features some of my other work - to include my other websites, combat sports analytics resources I’ve created, etc.\nFor those wondering where the name LiteralFightNerd came from, I began sharing my early quantitative MMA analysis on Twitter and Reddit. In September 2020, I posted a long piece to Reddit on a machine learning algorithm I created that predicts judging decisions by round in the UFC. That post received over 100 comments. The very first comment, which came almost immediately, read “literal fight nerd” (proof). A couple months later this blog was born in honor of one of Reddit’s finest.\nI literally am a fight nerd. Through this blog I hope to show that fight nerds can make substantive contributions to combat sports.\nEnjoy!\n-Nate"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog Posts",
    "section": "",
    "text": "Introducing Strike Accuracy Over Expected (SAOE)\n\n\n\n\n\nAn advanced striking metric that is easily interpreted, offers new insights, and facilitates meaningful comparisons between fighters\n\n\n\n\n\n\nMar 2, 2025\n\n\nNate Latshaw\n\n\n\n\n\n\n  \n\n\n\n\nIntroducing FightPickSim\n\n\n\n\n\nA UFC DraftKings DFS Projection, Simulation, & Optimization Tool\n\n\n\n\n\n\nJan 11, 2024\n\n\nNate Latshaw\n\n\n\n\n\n\n  \n\n\n\n\nVisualizing Fighter Styles\n\n\n\n\n\nAn exploratory look at how modern UFC athletes fight\n\n\n\n\n\n\nJan 5, 2022\n\n\nNate Latshaw\n\n\n\n\n\n\n  \n\n\n\n\nIntroducing Expected Rounds (xR)\n\n\n\n\n\nA new advanced fighter evaluation metric that is interpretable, informative, predictive, robust, and stable\n\n\n\n\n\n\nMar 2, 2021\n\n\nNate Latshaw\n\n\n\n\n\n\n  \n\n\n\n\nExtending JudgeAI\n\n\n\n\n\nAggregating JudgeAI’s round score predictions to generate final scorecard probability distributions - with a case study on the judging decisions made during the main event of UFC 247: Jones vs Reyes\n\n\n\n\n\n\nFeb 25, 2021\n\n\nNate Latshaw\n\n\n\n\n\n\n  \n\n\n\n\nIntroducing JudgeAI\n\n\n\n\n\nA machine learning algorithm that predicts judges’ scores by round in the UFC\n\n\n\n\n\n\nFeb 19, 2021\n\n\nNate Latshaw\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-02-19-introducing-judgeai/index.html",
    "href": "posts/2021-02-19-introducing-judgeai/index.html",
    "title": "Introducing JudgeAI",
    "section": "",
    "text": "Introduction\nFights in the Ultimate Fighting Championship (UFC) consist of 3 or 5 rounds, each of which lasts 5 minutes in duration. At any point in any round, the fight may end via knockout or submission. Otherwise, the winner of the fight is determined by the judges at the end of the final round. Each round is scored independently by 3 judges based on effective striking, effective grappling, octagon control, aggressiveness, and effective defense - in that order. Each judge awards 10 points to the winner of each round and 9 or fewer points to the loser (with some incredibly rare exceptions). Then, after the final round, each judge’s scores are added across rounds to arrive at the final scorecard. The fighter with more points for the majority of final scores is the winner of the fight.\nJudging decisions can be controversial. It’s often unclear how a particular judge came up with a certain seemingly unlikely score. Enter JudgeAI, a machine learning model that predicts round scores. If successful, JudgeAI will identify trends in the relationship between striking/grappling statistics and round scores given by the judges in order to quantify how likely or unlikely each possible score is for a round with a given set of statistics. While the publicly available statistics are far from a perfect measure of what the judges can see with their eyes throughout each round, it is my hope that these statistics are enough to proxy for the criteria judges use to score rounds such that JudgeAI need not watch a fight in order to accurately predict round scores.\nThe purpose of this post is twofold:\n\nCreate a machine learning algorithm, JudgeAI, that utilizes publicly available round-level statistics and judging decisions to predict round scores.\nDevelop a methodologically sound framework to properly illustrate how JudgeAI would have performed had it been implemented in the past in order to provide a valid measure of how well the model will perform in the future.\n\nOne final note before we get started: this post is primarily methodological in nature, which is admittedly off-putting to some. This post serves to illustrate what I did, how I did it, and how JudgeAI performs. I plan to use this post and the methodology described herein as a foundation for a number of derivative results and metrics that are hopefully much more accessible to those who enjoy the UFC but are not interested in these methodological details. It is my hope that this post will be a comprehensive reference for anyone interested in what’s happening with JudgeAI under the hood.\n\n\nUFC data exploration\nAccording to official UFC statistics, there were 4,399 fights in the UFC between 2011-2020, 48.3% of which resulted in a winner being declared by the judges’ scorecard. The figure below shows how UFC fights ended over this period. This post will focus on split and unanimous decisions only. A split decision occurs when the 3 judges do not all agree on which fighter won the fight, while a unanimous decision occurs when all 3 judges have the same winner on the final scorecard. Fortunately, the figure below shows that the number of split decisions is not noticeably rising over the past few years. Instead, if anything, judges are agreeing with each other at higher rates at the end of the decade, as measured by the proportion of decisions that are unanimous.\n\n\n\n\n\n\n\n\n\nUsing data from MMADecisions, we explore how judges score fights by round. However, we first have to combine the judging data with the official UFC statistics data. As a result, we lose some fights. First, we drop all fights that do not end in a decision by the judges since scorecards are not publicly reported for any of the rounds in these fights. Then, we drop rounds where judging data was otherwise not available or where judges gave scores other than 10-8, 10-9, 9-10, or 8-10 since these potentially indicate a penalty where a point was deducted from one of the fighters (or other rare edge cases). By the end, of the 2,125 UFC fights between 2011-2020 where a winner was declared by the judges, 1,670 fights (containing 5,238 rounds) are successfully merged with the judging decisions data and retained for analysis. Unless otherwise stated, all subsequent counts and statistics refer to this set of fights, which comprises 78.6% of fights in which the judges selected a winner and 38.0% of all UFC fights between 2011-2020.\nIn order to predict round scores, we need to determine the “ground truth” score for each round. This is an inherently impossible task because if we had the ground truth then we would not need judges. Hence, we consider the “true” score of the round to be the score given by the majority of judges (i.e. at least 2 out of the 3 judges). Of the 5,238 rounds under consideration, all 3 judges provided the same score for 76.9%, or 4,029 rounds.\nIn the UFC, fighters are assigned to either the red corner or the blue corner. For title fights, the defending champion is always the red corner and the challenger is always the blue corner. For all other fights, the reasoning behind the corner assignments is not quite clear (at least not to me), but the red corner generally appears to be the more well-known and/or more experienced fighter. The figure below shows how rounds were scored between 2011-2020 (using the “true” round score), where the reported scores follow the convention: Red Corner Score - Blue Corner Score.\nWe see in the figure that red corners win more often than blue corners in each year. Over the entire period, the red corner won 57.6% of all rounds considered. Also, notice that 10-8 and 8-10 rounds are incredibly rare, comprising only 3.3% of all rounds considered.\n\n\n\n\n\n\n\n\n\nRecall that our goal is to develop a machine learning algorithm that predicts judges’ scores using the statistics accumulated in each round. However, before we do that, we first consider a simple, baseline decision rule that predicts round winners to which we can compare our eventual model’s performance. That is, the baseline decision rule predicts that whichever fighter landed more significant strikes in a round is the winner. Among rounds in which each fighter landed the same number of significant strikes, the fighter who landed more total strikes is predicted to be the winner. Finally, among the rounds remaining where each fighter landed the same number of significant and total strikes (only 0.9% of all rounds considered), the red corner is predicted to be the winner.\nTable 1 below shows how well our baseline decision rule is able to predict round winners across time. We see that the baseline rule performs relatively well in each year, which makes sense since the baseline only considers striking and since effective striking is the metric given the highest priority in the judges’ decision making. Of all rounds considered, the baseline rule correctly predicts the winner 77.8% of the time.\n\n\n\n\nTable 1:  Baseline Round Winner Accuracy by Year \n \n  \n    Year \n    Number of Rounds \n    Baseline Round Winner Accuracy \n  \n \n\n  \n    2011 \n    237 \n    79.3% \n  \n  \n    2012 \n    353 \n    80.5% \n  \n  \n    2013 \n    348 \n    74.7% \n  \n  \n    2014 \n    533 \n    76.9% \n  \n  \n    2015 \n    604 \n    78.5% \n  \n  \n    2016 \n    584 \n    75.0% \n  \n  \n    2017 \n    562 \n    78.5% \n  \n  \n    2018 \n    556 \n    79.1% \n  \n  \n    2019 \n    766 \n    77.3% \n  \n  \n    2020 \n    695 \n    78.8% \n  \n\n\nNote: \n\n -Baseline decision rule predicts the winner as the fighter who landed more significant strikes. Ties go to whoever landed more total strikes, or the red corner if total strikes are also even.-\"Round Winner Accuracy\" is defined as the share of rounds in which the predicted round winner matches the winner declared by the majority of judges.\n\n\n\n\n\n\nNow that we have established a baseline decision rule, we proceed with building the predictive model, JudgeAI. The baseline decision rule only considers strikes landed, while the actual model will consider many more features for each round. If the eventual predictive model is any good, it will predict round winners more successfully than this simple baseline rule.\n\n\nBuilding JudgeAI\nThe outcome of interest for JudgeAI is the score given by the majority of judges for each round. That is, the outcome will be one of 10-9, 10-8, 9-10, or 8-10, and again, the scores follow the convention: Red Corner Score - Blue Corner Score. JudgeAI will use the statistics accumulated by each fighter during each round to predict the outcome. The official UFC statistics provide striking and grappling statistics, to include total strikes landed and attempted, significant strikes landed and attempted, knockdowns, takedowns landed and attempted, submission attempts, reversals, and control time. In addition, significant strikes are broken down into strikes to the head, body, or legs; and strikes at distance, in the clinch, or on the ground. Using strikes and takedowns landed and attempted, we also compute striking and takedown accuracy, respectively. Finally, rather than including each fighter’s round-level statistics separately in the model, we instead include the difference by taking the red corner’s statistic minus that of the blue corner, for each statistic included. In total, there are 31 features included in the model, all of which are statistical differences.\nPut more simply, each observation in the model is a single round where the outcome is the score given by the majority of judges, and the features used to predict each majority score are the differences between each fighter’s accumulated statistics. For example, one feature in the model is the difference in total strikes landed for each round, which is computed by subtracting the number of total strikes landed by the blue corner from the number of total strikes landed by the red corner.\nSince we are predicting scores over time and since judging and fighter tendencies can change over time, we employ time series cross validation to train and evaluate our predictions. That is, for each month in the period, beginning with January 2012, we train the model using data from all prior months in the period and then make predictions on the single month under consideration. Table 2 below illustrates the time series cross validation strategy where a series of models is trained, each of which predicts scores for a single month of fights (“Evaluation Month” from the table) using all prior data in the period (“Training Months” from the table). Using time series cross validation, we obtain predictions for every month in the “Evaluation Month” column of the table below.\n\n\n\n\nTable 2:  Time Series Cross Validation Strategy \n \n  \n    Training Months \n    Evaluation Month \n  \n \n\n  \n    January 2011 - December 2011 \n    January 2012 \n  \n  \n    January 2011 - January 2012 \n    February 2012 \n  \n  \n    January 2011 - February 2012 \n    March 2012 \n  \n  \n    ... \n    ... \n  \n  \n    January 2011 - October 2020 \n    November 2020 \n  \n  \n    January 2011 - November 2020 \n    December 2020 \n  \n\n\nNote: \n\n -Data in the \"Training Months\" are used to build each model. Predictions are then made on data in the \"Evaluation Month\".\n\n\n\n\n\n\nThis modeling strategy contains 3 key advantages over a more simple approach of splitting the data into a training and test set - these advantages are:\n\nAll predictions are made on fights unseen by the model through which predictions are made (i.e. we use out-of-sample predictions only).\nWe recover predictions for the entire period, except for fights in 2011. Since 2011 is the first year we have data, we only use it for training.\nWe are not “cheating” by using a model trained on fights that come after the fights on which we are predicting. This more accurately simulates how successful JudgeAI would have performed had it been implemented in the past, and it gives us a better sense of how well JudgeAI will perform going forward.\n\nThese 3 advantages are significant and essential to the validity of the model evaluation section. Without (1), we would be making predictions on rounds that the model has already seen, which would incorrectly inflate the performance. Further, advantage (2) is important because it provides us with a large sample by which to evaluate model performance, which gives us a more robust estimate of future performance. Finally, without (3), the model would not accurately convey historical performance. For example, if the model is trying to predict round scores for fights in 2014 but is trained using rounds from 2018, the resulting performance would not be realistic because the model is using fights that have not happened yet to make predictions.\nThe algorithm I’ve chosen to use is random forests since it quickly and efficiently builds an ensemble of decision trees to make predictions without overfitting. Also, decision trees are able to capture complex interactions between features, which means we do not have to specify which combinations of features should be considered in conjunction with one another; instead, the algorithm will detect these relationship automatically by design. Each algorithm in the time series cross validation is trained using 500 decision trees to grow a probability forest. Hence, for each round, the algorithm provides a predicted probability of each possible score out of the scores 10-9, 10-8, 9-10, and 8-10.\n\n\nEvaluating JudgeAI\nAfter performing time series cross validation, we now have a predicted probability of each possible score for each round in our sample (again, excluding fights in 2011). After aggregating these round score probabilities up to round win probabilities, the figure below shows how well these round win probabilities are calibrated. If JudgeAI yields well-calibrated probabilities, then we should observe, for example, the red corner winning approximately 60% of rounds in which JudgeAI gives the red corner around a 60% probability of winning. In other words, the figure below checks whether the round win probabilities mean what we want them to mean. Each point represents a group of rounds with both (a) red corner predicted win probabilities centered around the corresponding points on the horizontal axis, and (b) observed red corner win shares equal to the corresponding points along the vertical axis. Points that hug the displayed 45 degree line are considered well calibrated. Since this is real-world data, perfect calibration is not expected, and overall, this figure is quite promising. In aggregate, JudgeAI’s predicted round win probabilities do more or less reflect the share of rounds won historically.\n\n\n\n\n\n\n\n\n\nUsing the predicted probabilities for each possible score, we define the predicted score as the score with the highest predicted probability from the model. We then compute the scoring accuracy of the model by determining the number of rounds in which the predicted score matches the score given by the majority of the judges and then dividing by the total number of rounds. That is,\n\\[\n\\text{Scoring accuracy} = \\frac{\\text{rounds where predicted score = judges' majority score}}{\\text{total number of rounds}}.\n\\]\nOver all fights considered between 2012-2020, the model’s scoring accuracy is 80.2%, which means that the model agrees with the majority of judges on the particular score in approximately 4 out of every 5 rounds.\nDiving deeper into performance metrics, the model predicts the same round winner as the majority of judges in 83.3% of rounds. An example of the difference between this measure and the scoring accuracy reported before would be a round where the model’s predicted score is 10-9, but the majority of judges score it 10-8. Both the model and the judges have the same round winner, but they disagree on the particular score of the round.\nWhile JudgeAI performs well based on how frequently it agrees with the majority of judges, it is also beneficial to see how often it agrees with any judge. If all 3 judges agree on a particular round score or round winner, it is much more likely that this score or winner is objectively correct. Hence, JudgeAI should very rarely give a predicted score or predicted round winner that disagrees with every judge. Fortunately, such occurrences are rare. The model’s predicted scores match at least 1 judge’s score in 90.8% of rounds. Likewise, the model’s predicted round winner matches that of at least 1 judge in 92.3% of rounds.\nFurther, the figure below displays the model’s performance by year and shows that performance is both strong and consistent across time. To the extent that judging biases or preferences change over time, the model adapts well without any egregious degradation. Similarly, as the sport of mixed martial arts (MMA) evolves over time, the judges may modify their internal interpretations of the scoring criteria in order to consistently and fairly score fights. Based on the consistency of the model’s performance over time, the evolution of the sport across the period does not appear to adversely impact the generalizability of the model.\n\n\n\n\n\n\n\n\n\nTable 3 below compares the model’s performance to the aforementioned baseline decision rule with respect to round winner accuracy. In each year considered, the model is more accurate at determining round winners, which is expected since it accounts for more than just strikes landed. Moreover, the model is significantly more valuable than the baseline because it makes predictions for each possible round score, instead of only the round winner, and it assigns a probability to each possible outcome, instead of just a binary prediction. Ultimately, the baseline decision rule is not a tough bar to clear, but it is nonetheless encouraging that our model is a drastic improvement over a hypothetical judge that only considers strikes landed and ignores all other aspects of the fight.\n\n\n\n\nTable 3:  Comparing Round Winner Predictions by Year \n \n  \n    Year \n    Number of Rounds \n    Baseline Round Winner Accuracy \n    JudgeAI Round Winner Accuracy \n  \n \n\n  \n    2012 \n    353 \n    80.5% \n    83.0% \n  \n  \n    2013 \n    348 \n    74.7% \n    83.3% \n  \n  \n    2014 \n    533 \n    76.9% \n    84.2% \n  \n  \n    2015 \n    604 \n    78.5% \n    84.1% \n  \n  \n    2016 \n    584 \n    75.0% \n    81.3% \n  \n  \n    2017 \n    562 \n    78.5% \n    83.5% \n  \n  \n    2018 \n    556 \n    79.1% \n    84.5% \n  \n  \n    2019 \n    766 \n    77.3% \n    82.2% \n  \n  \n    2020 \n    695 \n    78.8% \n    83.7% \n  \n\n\nNote: \n\n -\"Round Winner Accuracy\" is defined as the share of rounds in which the predicted round winner matches the winner declared by the majority of judges.\n\n\n\n\n\n\nFinally, to unpack the model a bit more and see which statistics it relies upon the most to score rounds, we use feature importance. Table 4 below displays the top 10 most important features in the model, where importance is essentially defined as how helpful the feature is in predicting the outcome. Again, when scoring a round, judges are supposed to consider effective striking, effective grappling, octagon control, aggressiveness, and effective defense - in that order. Examining the table below shows that JudgeAI appears to be capturing the exact same criteria in nearly the exact same order. This promising result suggests that both (a) judges generally follow the criteria with which they are provided, as expected, and (b) JudgeAI is able to use the round-level statistics to effectively capture this criteria when predicting round scores.\n\n\n\n\nTable 4:  Top 10 Most Important Model Features \n \n  \n    Rank \n    Feature \n    Corresponding Judging Criteria \n  \n \n\n  \n    1 \n    Difference in significant strikes landed \n    Effective striking \n  \n  \n    2 \n    Difference in total strikes landed \n    Effective striking \n  \n  \n    3 \n    Difference in control time \n    Octagon control, effective grappling \n  \n  \n    4 \n    Difference in significant strikes landed to the head \n    Effective striking \n  \n  \n    5 \n    Difference in total strikes attempted \n    Aggressiveness \n  \n  \n    6 \n    Difference in significant strikes attempted \n    Aggressiveness \n  \n  \n    7 \n    Difference in significant strike accuracy \n    Effective striking, effective defense \n  \n  \n    8 \n    Difference in significant strike accuracy to the head \n    Effective striking, effective defense \n  \n  \n    9 \n    Difference in significant strikes attempted on the ground \n    Effective grappling \n  \n  \n    10 \n    Difference in total strike accuracy \n    Effective striking, effective defense \n  \n\n\nNote: \n\n -Feature importance is computed on a model including all rounds in the period, as opposed to using one of the models created via time series cross validation.-Differences are computed by subtracting each blue corner statistic from the corresponding red corner statistic.\n\n\n\n\n\n\n\n\nLimitations of JudgeAI\nI’d like to clearly state that JudgeAI is not perfect. I am not claiming that it is better than any particular judge, nor am I suggesting that it should replace judges in the UFC.\nWhile the consistently strong performance of JudgeAI over time is promising, this algorithm does have serious limitations. First and foremost, statistics do not perfectly convey damage dealt. Effective striking is the primary judging criteria, and even though accumulating many more significant strikes than one’s opponent does correlate with dealing more damage, just looking at statistical differences will not replace what we can see from watching a fight. This issue is especially problematic in rounds that are close statistically but not as close when you watch it because one fighter clearly lands harder blows.\nFurther, JudgeAI seeks to uncover longer-term trends in the relationship between round scores and the features included in the model. Therefore, JudgeAI uses these broader relationships to score every round no matter what, but in reality, many rounds include some sort of rare occurrence, like a devastating calf kick that leaves a fighter largely immobile, that can and perhaps should sway the judges but will go unnoticed by the model. Similarly, the model only sees the aggregate statistics for each round, so if a particular fighter starts slow in the first half but dominates the second half of a round, the judges might give this round to the strong finisher while the model might not.\nFinally, the vast majority of rounds are scored 10-9 for the winner. As a result, JudgeAI struggles to predict 10-8 rounds with a high probability, even when the striking statistics are wildly lopsided. There are methodological adjustments that could be made to increase the model’s precision in this regard, but I have not yet explored such changes.\n\n\nExtending JudgeAI\nThe most obvious extension of JudgeAI would be aggregating the round-level predictions to produce a distribution of potential final scores. Since JudgeAI produces round score probabilities instead of just round win probabilities, it is possible to use the model’s predictions to generate a complete probability distribution for every possible final score. This would allow us to account for the underlying uncertainty in the round-level scoring while identifying the most likely final score.\nWhile JudgeAI cannot be used to definitively say that a particular judge gave the wrong score for a particular round, it can be used to assess judges over a larger sample of fights. Since the model is calibrated to reflect the majority decision of judges and since it is largely successful in doing so over time, identifying any judges whose scores regularly deviate from JudgeAI’s scores over a large sample of fights could be fruitful.\nFinally and most importantly, I believe JudgeAI can be leveraged to create brand new advanced metrics for MMA. Baseball has expected runs that uses statistics from within an inning to essentially compute the number of runs a team would expect to score, on average, after generating those statistics. Likewise, soccer has expected goals that uses the probability of scoring on each shot a team takes over the course of a game to calculate the total number of goals a team would expect to score, on average, after taking shots from those locations. I believe JudgeAI’s predicted round win probabilities can be used to create expected rounds, a metric that measures the number of rounds fighters would expect to win, on average, after compiling their observed round-level statistics. If successful, this new metric can move the sport away from looking at win percents or finish percents and towards a more informative metric that describes how dominant each fighter is on a round-by-round basis."
  },
  {
    "objectID": "posts/2021-02-25-extending-judgeai/index.html",
    "href": "posts/2021-02-25-extending-judgeai/index.html",
    "title": "Extending JudgeAI",
    "section": "",
    "text": "Introduction\nIn my previous blog post, I introduced JudgeAI, a machine learning algorithm that uses round-level statistics to predict judges’ scores by round in the UFC. That post illustrated in detail how JudgeAI was built and how it performs across time. Overall, the model provides well-calibrated round win probabilities and is able to predict round scores with high accuracy. I strongly suggest reading that post if you are interested in understanding the methodological details of JudgeAI. Alternatively, if you’re interested in a quicker summary of the details of an earlier version of the model, you can check out my posts on Reddit and Twitter - those social media posts combine the information presented in this blog post and my previous post. This post largely assumes you either understand the technical details of JudgeAI or do not care about such details - either is perfectly fine.\nThis post seeks to extend JudgeAI by leveraging its round score probabilities to produce a probability distribution of all possible final scores. I hope audiences of all types find this post approachable. We explore the methodology by taking a look at the Jon Jones vs Dominick Reyes fight from UFC 247 on February 8, 2020, which was a unanimous, but controversial, decision by the judges. I also include a brief methodology section for those interested in how the round score probabilities are aggregated to produce final scorecard predictions.\nAs we will see, using JudgeAI’s round score probabilities to generate a distribution of final scores is a powerful way to utilize the underlying uncertainty in the round-level scoring, and then propagate that uncertainty across rounds, to understand how likely or unlikely each possible final score is. It also allows us to move away from thinking about discrete scores and move towards thinking probabilistically about judging decisions.\n\n\nCase study: Jon Jones vs Dominick Reyes\n\nRound 1\nThe figure below shows a number of statistics from the first round of Jones vs Reyes. Note that JudgeAI includes many more features than those shown here. The figure also displays the score given by each judge, the score given by JudgeAI, and JudgeAI’s probability of each score in 10-9, 10-8, 9-10, and 8-10.\nWe see that Reyes landed more significant strikes and only absorbed a single strike to the head. All 3 judges and JudgeAI scored this round 9-10 in favor of Reyes. Also, JudgeAI shows high confidence in its predicted score by placing an 81% probability on the majority of judges giving that score.\n\n\n\n\n\n\n\n\n\n\n\nRound 2\nThe figure below shows round 2. We see that Reyes landed 50% more significant strikes than Jones, and he landed more strikes to each of the head, body, and legs. JudgeAI again scored this 9-10 to Reyes. However, 2 of the 3 judges scored the round 10-9 to Jones.\nIt is important to note here that JudgeAI is not perfect. The model identifies broad trends in the relationship between round-level statistics and judges’ scores. Here the model is essentially saying that rounds with these striking differentials (plus all other statistics considered but not shown) go to the fighter who landed more strikes, which is Reyes here, around 3 out of every 4 times. While JudgeAI placed a high probability on Reyes winning this round, we cannot say for sure that 2 of the judges got this round wrong. Though striking differentials often correlate with damage dealt, for example, the model does not perfectly account for this. It is possible that Jones dealt more damage even though he landed fewer strikes.\nFinally, notice that JudgeAI was less certain about this 9-10 score than in the previous round. There is uncertainty in round-level scoring because judges are subjective and see different things in each round. This uncertainty propagates across rounds and can result in seemingly strange final scores. Hence, it is more important to focus on JudgeAI’s score probabilities than its predicted score of 9-10.\n\n\n\n\n\n\n\n\n\n\n\nRound 3\nRound 3 scores and statistics are displayed in the figure below. We see that Reyes again landed more significant strikes than Jones, and again, JudgeAI scored this round 9-10 to Reyes. However, 2 of the 3 judges scored this round 10-9 to Jones.\nOver rounds 2-3, either JudgeAI missed some important factor(s) in the fight, like damage dealt discrepancies, or it is safe to say that the judges were not doing Reyes any favors. The judges were split on the last 2 rounds, which suggests these rounds were tight, even though Reyes had the striking advantage on paper in both rounds.\n\n\n\n\n\n\n\n\n\n\n\nRound 4\nThe figure below shows round 4. We see that Jones landed more strikes than Reyes overall and to each of the head, body and legs. In addition, Jones landed the only takedown of the round and accumulated nearly 1 minute of control time. JudgeAI scored this round 10-9 to Jones with a very high probability, and all 3 judges agreed.\n\n\n\n\n\n\n\n\n\n\n\nRound 5\nThe final round is displayed below. Jones landed more significant strikes than Reyes and secured a takedown with around 30 seconds of control time. As in the last round, JudgeAI scored this round 10-9 to Jones with a high probability, and all 3 judges agreed.\n\n\n\n\n\n\n\n\n\n\n\n\nMethodology: computing final scorecard probabilities\nThis section provides a quick overview of the methodological details involved in computing the forthcoming final score probabilities. If that is not something that interests you, feel free to skip to the next section.\nRecall that our goal is to utilize JudgeAI’s round score probabilities to produce a probability distribution of all possible final scores. Such a distribution will provide more information than a discrete final score, like 48-47. Instead, the distribution will show how likely or unlikely each final score is after accounting for the uncertainty in round scoring that propagates across rounds.\nSince JudgeAI returns predicted probabilities for each score in 10-9, 10-8, 9-10, and 8-10, mathematically deriving the probability of each possible final score after 3 or 5 rounds is cumbersome. Hence, we instead use a Monte Carlo method to numerically compute final scorecard probabilities. That is, we essentially simulate the scoring of each round many times using JudgeAI’s round score probabilities and then see what proportion of simulated fights had each final score.\nThe computational algorithm employed is below.\n\nDraw 1 sample score for each round using JudgeAI’s corresponding round score probabilities. That is, for each round, draw a sample score from the possible scores 10-9, 10-8, 9-10, and 8-10 where the probability of drawing each possible score is set to the corresponding round score probability provided by JudgeAI.\nAdd each fighter’s sample scores together across rounds to generate the sample final score for the fight.\nRepeat the 2 steps above 100,000 times. This yields 100,000 final score samples.\nCompute final scorecard probabilities by dividing the number of times each final score appears in the samples by 100,000.\n\n\n\nJones vs Reyes final scorecard\nThe figure below shows the final scorecard for the fight and, according to JudgeAI coupled with the Monte Carlo method outlined above, the probability of each possible final score. We see that all 3 judges had Jones winning. However, if we add up JudgeAI’s predicted scores by round, we find that JudgeAI scored the fight 47-48 in favor of Reyes. Without properly aggregating JudgeAI’s round score probabilities, our analysis would end here, but fortunately, we recover a probability distribution of final scores that enables much more in-depth analysis.\nUsing the aforementioned algorithm to aggregate round score probabilities, we see that the most likely final score of 47-48 in favor of Reyes is expected to occur with a 43% probability. In other words, JudgeAI predicts that over many fights with the exact same round-level statistics as this fight, Reyes would win the decision 47-48 around 43% of the time.\nFurther, Reyes’ win probability (computed by adding up the appropriate final score probabilities) was 55%. Again, this means that over many fights with identical round-level statistics, JudgeAI predicts that Reyes would win via decision more often than not.\n\n\n\n\n\n\n\n\n\nEven though JudgeAI has Reyes winning this fight, notice that the win probability was barely over 50%. According to JudgeAI, the two most dominant rounds were 4 and 5, both of which went to Jones. This means that JudgeAI was more certain that the judges would also give these rounds to Jones, which turned out to be true as Jones won those rounds 10-9 on every scorecard. Since rounds are scored independently, once a fighter in a 5 round fight secures 2 dominant rounds, the math begins moving in that fighter’s direction. As we saw, JudgeAI had Reyes winning the other 3 rounds, which should be enough to win the decision. However, since Reyes’ round wins (according to JudgeAI) were less dominant, it was more likely that some judges would award some of those rounds to Jones, which is also what we saw.\nThis is the difference between using JudgeAI to score rounds probabilistically vs keeping track of one’s own personal round scores at home. The latter can lead to confusion or anger when comparing one’s own final score to that of the judges, while the former is more likely to help us understand how likely or unlikely a particular judge’s final score was. In this case, according to JudgeAI, two judges scoring the fight 48-47 to Jones was not terribly egregious, but the 49-46 score to Jones was relatively unlikely.\nIn the end, after accounting for the round-level scoring uncertainty, JudgeAI had Reyes winning with a 55% probability, which is quite low coming from a model that had Reyes winning 3 rounds. In this case, the uncertainty captured by JudgeAI lowered Reyes’ win probability from what we might have expected and happened to coincide with Jones winning the fight on each judge’s scorecard. Though JudgeAI still disagrees with the judges on the winner of the fight, the model only awarded Reyes a 55% win probability, which makes this fight a toss up.\nWhile the judges all agreed that Jones won the fight and JudgeAI had the fight as a toss up, the community seems to feel much more strongly that Reyes won. According to MMADecisions, which posts the official scorecards along with scores provided by members of the media and by fans, 14 of the 21 media members scored the fight 47-48 in favor of Reyes. The other 7 members of the media scored it 48-47 to Jones. In addition, as of the writing of this post, 77% of the fans who submitted scores had Reyes winning, the majority of which scored it 47-48 to Reyes. The scores provided by the community align with the two most likely final scores according to JudgeAI, but the share of media members and fans awarding the fight to Reyes is much higher than JudgeAI’s win probability for Reyes. Thus, the actual final scorecard submitted by the judges was generally much more surprising to media members and fans than it was to JudgeAI, which is likely due to the probabilistic decision-making of JudgeAI that is typically challenging for humans, and especially passionate fans, to replicate on their own.\n\n\nConclusion\nThe purpose of this post was not to argue that Reyes should have won the Lightweight title against Jones at UFC 247. Instead, this post serves to illustrate how the round score probabilities provided by JudgeAI can be aggregated to produce a probability distribution of final scores that is both unique and insightful.\nWe saw how using JudgeAI’s discrete round scores to score the fight resulted in a final score that did not match any of the judges on the final scorecard. However, leveraging JudgeAI’s round score probabilities allowed us to think probabilistically about how likely each final score might be. That is, we saw that Jones won the 2 most dominant rounds and thus only needed to win 1 of the 3 more competitive rounds on the judges’ scorecard. Hence, even though JudgeAI had Reyes winning the 3 more closely contested rounds, it only gave Reyes a 55% chance of winning the decision because of all the uncertainty in how judges were likely to score those 3 rounds. Media members and fans had Reyes winning at significantly higher rates than JudgeAI. While the resulting frustration among members of the media and fans may or may not be justified, I think that scoring a fight probabilistically with JudgeAI provides the community with valuable insights that are tough to get anywhere else."
  },
  {
    "objectID": "posts/2021-03-02-introducing-expected-rounds-xr/index.html",
    "href": "posts/2021-03-02-introducing-expected-rounds-xr/index.html",
    "title": "Introducing Expected Rounds (xR)",
    "section": "",
    "text": "Introduction\n\nCurrent quantitative fighter evaluation limitations\nQuantitative mixed martial arts (MMA) analysis features two recurring challenges: dealing with small samples sizes and capturing the nuance that is inherent to the sport. Mainstream fighter evaluation metrics do not properly address these challenges.\nIn general, fighters do not have many professional MMA fights, and among their limited number of fights, the Ultimate Fighting Championship (UFC) is really the only MMA promotion that publicly tracks striking and grappling statistics from within each fight (though there are some exceptions). Hence, the amount of data that can be collected on each professional UFC fighter is limited, which makes quantitative analysis difficult.\nFurther, MMA is a sport that features many different fighting styles and techniques that are difficult to quantify. Fights can end at any moment via knockout or submission, so there are a number of paths to victory for fighters that possess expertise in multiple MMA disciplines. However, finishing ability is not the only signal of dominance in MMA. Proper fighter evaluation metrics should not only measure finishing ability but should also capture other forms of dominance inside the octagon.\nCurrently, fighters are frequently evaluated on their win percent (number of fights won divided by total number of fights) and finish percent (number of fights won via knockout or submission divided by number of fights won). However, both of these metrics are limited. In addition to small sample size issues, win percent fails to differentiate between close wins, dominant wins, and judging blunders. Finish percent measures a fighter’s ability to finish a fight, but as a broader measure of fighter dominance, it does not account for dominant wins by decision, which are arguably just as impressive as finishes.\n\n\nPushing the envelope with xR\nEnter Expected Rounds (xR) and Expected Round Percent (xR%), new advanced metrics that aim to address the sample size and nuance issues that typically plague other fighter evaluation measures. There are many reasons why I believe the MMA community could benefit from these metrics.\nFirst and foremost, as an advanced metric, xR is interpretable and easy to understand:\nxR is the number of rounds a fighter would expect to have won, on average, given his or her round-by-round performances.\nThat’s it. Anyone who can understand that is capable of adopting this metric. The accompanying metric xR% is then just as straightforward:\nxR% is the percent of rounds a fighter would expect to have won, on average, given his or her round-by-round performances.\nThe rest of this post will cover the methodological details of these metrics and then step through a number of reasons why MMA audiences of all types should care about xR and xR%. However, I want it to be stated clearly up front that these are advanced metrics that are approachable for everyone. If the methodological details of these metrics do not interest you, feel free to skip over that section.\nYou do not need to understand precisely how these metrics are computed in order to understand what they seek to measure and how they improve on current mainstream fighter evaluation metrics like win percent and finish percent.\n\n\nWhy you should care about xR\nBefore jumping into the methodology, below I’ve listed five reasons why I believe xR and xR% should be embraced by the MMA community.\n\nxR and xR% are interpretable\nxR% is more informative than win percent and finish percent\nxR% is more predictive than win percent and finish percent\nxR% is more robust to judging blunders than win percent\nxR% is more stable than win percent\n\nThe first reason, interpretability, has already been covered. It is my goal in this post to justify the remaining four reasons while ensuring that all readers are able to understand and interpret the figure below, which shows the career xR% of all current UFC champions.\n\n\n\n\n\n\n\n\n\n\n\n\nMethodology\nThe xR metric is an extension of a machine learning algorithm I developed in a previous blog post. That algorithm uses official UFC round-level striking and grappling statistics to predict judges’ scores by round. The algorithm used to create xR is trained on 1,670 UFC fights that all ended in a decision by the judges across 2011-2020.\nNote that to avoid overfitting, for each fight within a given year in 2011-2020, xR is computed using an algorithm trained on fights in all other years within 2011-2020. As an example, for each fight in 2014, xR is created using an algorithm trained on fights in 2011-2013 and 2015-2020. Then, for all fights outside of 2011-2020, xR is generated using all 1,670 fights in the 2011-2020 sample. This paradigm balances the need to avoid overfitting caused by training and predicting on the same fights with the consistency that comes from computing a metric using (nearly) the same algorithm over all of UFC history and into the future.\nAs demonstrated in my prior post, the algorithm is able to predict round scores with a high degree of accuracy and generate well-calibrated probabilities for each possible round score. That is, for each round in the UFC, we use the algorithm to recover the probability that the judges will score the round 10-9, 10-8, 9-10, or 8-10. Then, using these round score probabilities, we compute the probability of each fighter winning that round.\nFor each round that does not end via knockout or submission, xR is simply the probability that a particular fighter won the round. Hence, xR treats each round as a single point that is up for grabs and uses round win probabilities to partition that point between the two fighters. Then, for each round that ends in a knockout or submission, the winning fighter’s xR for that round is 1 and the losing fighter’s xR for that round is 0. The equation below defines xR for a given fighter as a piece-wise function.\nxR for a given fighter and round: \\[\\begin{equation}\nxR =\n\\begin{cases}\n0 & \\text{if fighter loses by knockout/submission} \\\\\n\\text{round win probability} & \\text{if round goes the distance} \\\\\n1 & \\text{if fighter wins by knockout/submission}\n\\end{cases}\n\\end{equation}\\]\nNotice that xR is computed by round, so for instance, a fighter who wins a fight via a second round submission will likely not capture all available xR for that fight. Instead, the first round’s xR will be partitioned according to each fighter’s round win probability, and then all of the second round’s xR will be given to the fighter who won by submission.\nMore concretely, consider Table 1 below of a hypothetical fight between Fighter A and Fighter B where Fighter A lands fewer strikes in the first round than his opponent but then wins by submission in the second. Here we see that xR is computed for each round independently of all other rounds. Then, aggregating xR up to the fight level yields the number of rounds each fighter could expect to have won, on average, given their performances in each round.\nEven though Fighter B landed more strikes in the first round, there is uncertainty in how the judges would have scored this round, so Fighter A still gets some credit for that round. However, since Fighter A earned a submission in the second round, the entire round’s worth of xR goes to him. Thus, on average, Fighter A could expect to win 1.4 rounds if this exact fight was fought many times - sometimes he would lose the first round on the judges’ scorecard but other times he would win it. The xR metric attempts to capture the uncertainty in how rounds are scored by the judges, which separates it from traditional metrics like win percent and finish percent.\nFinally, we see below that xR% is computed by adding each fighter’s xR across rounds and then dividing by the number of rounds fought. At the fight level, this tells us what percent of rounds each fighter could expect to have won given their round-level performances. Computing xR% over a fighter’s career would then describe how dominant that fighter has been by round, which again separates xR from win percent and finish percent.\nIn the hypothetical example below, if this was Fighter A’s first fight, his win and finish percents would be 100%, but his xR would only be 70%, which would better reflect his body of work since it accounts for the first round where he likely lost.\n\n\n\n\nTable 1:  xR for a hypothetical fight \n \n  \n    Fighter \n    Round 1 xR \n    Round 2 xR \n    Fight xR \n    Fight xR% \n  \n \n\n  \n    A \n    0.4 \n    1.0 \n    0.4 + 1.0 = 1.4 \n    1.4 / 2 = 0.7 = 70% \n  \n  \n    B \n    0.6 \n    0.0 \n    0.6 + 0.0 = 0.6 \n    0.6 / 2 = 0.3 = 30% \n  \n\n\nNote: \n\n -In this example, Fighter A wins in the second round via submission.\n\n\n\n\n\n\nAgain, if you are interested in understanding the technical details of how each fighter’s round win probability is computed, feel free to check out my previous blog post that provides a detailed overview of the algorithm and its performance.\nUsing this methodology, we are able to compute each fighter’s xR and xR% for every single round in UFC history in which the round-level statistics are publicly available.\n\n\nxR is informative\nThe xR and xR% metrics are more informative fighter evaluation tools than mainstream metrics (like number of wins, number of finishes, win percent, and finish percent) because they value the characteristics of a fight that fighters strive to achieve. That is, xR rewards fighters for both dominance and finishing ability, and it can distinguish between fighters who just barely outperform their opponents and fighters who completely dominate their opponents.\nEarning a finish is not the only way to signal dominance in the octagon, so finish percent clearly does not tell the whole story. Further, win percent does not account for the difference between a close split decision win and a clear unanimous decision win, but everyone who watches these fights can often immediately tell the difference between the two.\nSince xR uses well-calibrated round win probabilities, a fighter’s xR and xR% for a close split decision is much lower, on average, than that of a dominant win. Table 2 below shows the average xR% earned by the winning fighter based on the method of victory. Not only is there a large difference between split and unanimous decisions, which further suggests that xR is being awarded appropriately, but we see that submissions and knockouts tend to result in even higher xR%. Hence, xR rewards both dominance and finishing ability in the octagon, unlike traditional fighter evaluation metrics.\n\n\n\n\nTable 2:  Average earned fight xR% among winners \n \n  \n    Method of Victory \n    Average Winner's Earned xR% \n  \n \n\n  \n    Split Decision \n    56.1% \n  \n  \n    Unanimous Decision \n    74.5% \n  \n  \n    Submission \n    88.8% \n  \n  \n    Knockout \n    90.0% \n  \n\n\nNote: \n\n -This table includes all UFC fights between 2011-2020.\n\n\n\n\n\n\nAs a more concrete example, Table 3 below shows the xR breakdown for the UFC 245 main event between Kamaru Usman and Colby Covington. The fight was close heading into the fifth round where Usman won by knockout. Conventional metrics like win percent and finish percent assigned this fight as a one for Usman and a zero for Covington. However, those metrics leave a lot to be desired in terms of descriptive value, which is exactly why we turn to xR.\nAccording to the underlying xR algorithm, Covington had a 71.8% probability of winning the first round on the judges’ scorecard, so his xR for this round was 0.718. No matter what happened in subsequent rounds, Covington would retain this xR for that round.\n\n\n\n\nTable 3:  xR for UFC 245 main event by round \n \n  \n    Round \n    Usman xR \n    Covington xR \n  \n \n\n  \n    1 \n    0.282 \n    0.718 \n  \n  \n    2 \n    0.308 \n    0.692 \n  \n  \n    3 \n    0.974 \n    0.026 \n  \n  \n    4 \n    0.284 \n    0.716 \n  \n  \n    5 \n    1.000 \n    0.000 \n  \n\n\nNote: \n\n -Usman won by TKO in round 5.\n\n\n\n\n\n\nThe aggregate xR and xR% for the fight are displayed in Table 4 below. We see that the xR% metric had this as a competitive fight. While Usman walked away with the majority of the available xR after earning the knockout, Covington also left with some xR for his efforts.\n\n\n\n\nTable 4:  Total xR and xR% for UFC 245 main event \n \n  \n    Fighter \n    xR \n    xR% \n  \n \n\n  \n    Kamaru Usman \n    2.85 \n    57.0% \n  \n  \n    Colby Covington \n    2.15 \n    43.0% \n  \n\n\nNote: \n\n -This table presents xR and xR% at the fight level.\n\n\n\n\n\n\nNotice how tight this fight was and how xR% reflected that while win percent and finish percent did not. The amount of information lost using conventional metrics is significant. Now imagine how wide that information gap could grow when you consider an entire fighter’s career. Relative to win percent and finish percent, xR% paints a much clearer picture of a fighter’s body of work across his or her career.\n\n\nxR is predictive\nTo justify my claim that xR% is more predictive than win percent and finish percent, I calculate each UFC fighter’s cumulative xR%, win percent, and finish percent prior to each fight in his or her UFC career. Note that I only use UFC statistics (not professional MMA statistics) to compute these metrics.\nThen, for xR%, I predict that the fighter with the higher xR% will win. For win percent, I predict that the fighter with the higher UFC win percent will win (and so on). Hence, each prediction is made using only information from each fighter’s prior UFC fights.\nNote that predictions cannot be made for every UFC fight. If either fighter is making a UFC debut, then we do not have these metrics available for the debut fighter, so no prediction is made. Likewise, if the two fighters in a given fight have the same win percent, for instance, then no prediction is made based on win percent, but xR% and finish percent predictions will still be made (assuming there are no ties among these metrics).\nWe attempt to make predictions for all 4,399 UFC fights in 2011-2020. Table 5 below shows the results. We see that xR% makes more predictions than win percent and finish percent (as a result of fewer ties in xR%) and correctly predicts a higher share of fights in nearly every single year under consideration. It is significant that xR% is able to both make more predictions and predict better. It is generally easier to find more predictive success by making predictions on a narrower subset of the data, but the promise of xR% does not rely on making fewer predictions.\nI am not claiming that xR% will get you rich in the betting markets. However, it is clear that xR% is a fighter evaluation metric that is more predictive of a given fight outcome than win percent and finish percent, and this has been true for essentially the entirety of the last decade.\n\n\n\n\nTable 5:  Predicting UFC fights with xR%, win %, and finish % \n \n  \n    Year \n    UFC fights \n    xR% predictions \n    xR% accuracy \n    Win % predictions \n    Win % accuracy \n    Finish % predictions \n    Finish % accuracy \n  \n \n\n  \n    2011 \n    300 \n    206 \n    53.9% \n    173 \n    53.8% \n    150 \n    49.3% \n  \n  \n    2012 \n    341 \n    252 \n    55.2% \n    213 \n    53.5% \n    170 \n    42.9% \n  \n  \n    2013 \n    386 \n    275 \n    56.4% \n    234 \n    56.8% \n    195 \n    49.2% \n  \n  \n    2014 \n    503 \n    333 \n    58.0% \n    274 \n    56.6% \n    236 \n    50.8% \n  \n  \n    2015 \n    473 \n    391 \n    55.2% \n    324 \n    52.2% \n    273 \n    53.1% \n  \n  \n    2016 \n    493 \n    386 \n    56.5% \n    340 \n    58.5% \n    293 \n    51.9% \n  \n  \n    2017 \n    457 \n    353 \n    57.2% \n    310 \n    52.6% \n    274 \n    44.5% \n  \n  \n    2018 \n    474 \n    369 \n    57.5% \n    330 \n    53.6% \n    282 \n    47.9% \n  \n  \n    2019 \n    516 \n    393 \n    55.0% \n    350 \n    52.6% \n    286 \n    54.2% \n  \n  \n    2020 \n    456 \n    351 \n    54.1% \n    325 \n    52.9% \n    249 \n    49.4% \n  \n  \n    Total \n    4,399 \n    3,309 \n    56.0% \n    2,873 \n    54.3% \n    2,408 \n    49.6% \n  \n\n\nNote: \n\n -Predictions are not made on all UFC fights because either the metric is the same for both fighters or the metric is unavailable since at least one fighter is making a UFC debut.\n\n\n\n\n\n\n\n\nxR is robust\nTo illustrate how xR is more robust against judging blunders than win percent, let’s consider Volkanovski vs Holloway 2 from UFC 251. According to many in the MMA community, Volkanovski’s split decision win was controversial. In fact, 67% of the media members whose scores were reported on MMADecisions had Holloway winning the decision.\nTable 6 below shows xR by round for this fight. We see that the machine learning algorithm used to generate xR agrees with the judges that Volkanovski won the fight. Our purpose here is not to argue whether xR is correct or incorrect for each round. Instead, I argue that either way, whether xR and the judges correctly scored the fight or not, the xR% metric does a better job than win percent at accurately representing each fighter’s performance in this fight.\n\n\n\n\nTable 6:  xR for Volkanovski vs Holloway 2 by round \n \n  \n    Round \n    Volkanovski xR \n    Holloway xR \n  \n \n\n  \n    1 \n    0.307 \n    0.693 \n  \n  \n    2 \n    0.484 \n    0.516 \n  \n  \n    3 \n    0.909 \n    0.091 \n  \n  \n    4 \n    0.849 \n    0.151 \n  \n  \n    5 \n    0.949 \n    0.051 \n  \n\n\nNote: \n\n -Volkanovski won the fight by split decision.\n\n\n\n\n\n\nTable 7 below shows the xR and xR% earned by each fighter for the fight. With respect to the official judging of this fight, there are two possible scenarios - either (a) the judges scored the fight correctly and Volkanovski deserved to win, or (b) the judges scored the fight incorrectly and Holloway deserved to win. Let’s examine each scenario in turn.\n\nIf the judges scored the fight correctly and Volkanovski deserved to win, then the xR% metric correctly awarded the majority of the xR available for the fight to Volkanovski. However, since this fight was close and since seemingly the majority of the MMA community had Holloway winning, it seems safe to say that a metric like win percent that leaves Holloway with nothing for his efforts is not representative of what occurred in the octagon. Instead, with xR%, Holloway earns xR equal to the amount of rounds he could have expected to win, on average, given his performance. Hence, in this case, xR% correctly scored the fight and more appropriately rewarded each fighter for his efforts.\nAlternatively, if the judges scored the fight incorrectly and Holloway deserved to win, then the xR% metric also incorrectly assigned xR to each fighter (since Volkanovski earned more xR for the fight). In this instance, Holloway unjustly takes a loss and his win percent suffers. If this had been a fight early in his career, Holloway’s win percent could have decreased significantly due to a mistake by the judges. However, even though xR is assigned poorly under this scenario, Holloway still receives around one-third of the available xR for the fight, which mitigates the hit to his career xR%. Therefore, even though both the judges and the underlying xR model incorrectly scored the fight, xR% at least provides Holloway with some credit.\n\nWe see that in either scenario xR% is both more informative (which we also discussed in a prior section) and more robust to judging blunders than win percent. In general, during tight fights that could go either way on the judges’ scorecard, xR% typically partitions the fight relatively evenly, but a fighter’s win percent is either getting a zero for a loss or a one for a win with no in between.\n\n\n\n\nTable 7:  Total xR and xR% for Volkanovski vs Holloway 2 \n \n  \n    Fighter \n    xR \n    xR% \n  \n \n\n  \n    Alexander Volkanovski \n    3.50 \n    70.0% \n  \n  \n    Max Holloway \n    1.50 \n    30.0% \n  \n\n\nNote: \n\n -This table presents xR and xR% at the fight level.\n\n\n\n\n\n\nFinally, while this does not necessarily fit into the argument on the robustness of xR% as metric, I wanted to comment on the xR distribution in this example. The xR for round 3 went almost entirely to Volkanovski, yet I believe it is safe to say that round 3 was particularly close in the eyes of all viewers. As one of those viewers, I personally disagree with the distribution of xR here. However, I went back and checked out the official statistics for each round of this fight, and Volkanovski had a clear edge in round 3 on paper. This illustrates a limitation of xR: sometimes statistics do not tell the whole story. If you look at the official statistics for round 3, you should clearly see why most of the xR was given to Volkanovski. When the statistics are misleading, like in round 3 of this fight, xR may sometimes struggle to properly reflect reality. Nevertheless, while xR is not a perfect metric, I would argue that the judges are not perfect either. Both are wrong at times, but as I argued in this section, xR% is closer to the truth than the judges when it is wrong since it essentially awards partial credit to each fighter.\n\n\nxR is stable\nWhen I discuss a fighter evaluation metric’s stability, I am really referring to the degree to which the metric can swing on a fight-to-fight basis. Stability is important because a fighter evaluation metric should represent the quality of a fighter and then only improve or degrade as quickly as the fighter it is measuring improves or degrades. Fighters can have a bad fight, so we do not want a metric to overreact to a single performance - that would make the metric unstable.\nTo defend the claim that xR% is a more stable metric than win percent, I will first use a conceptual argument and then provide a mathematical argument.\nFirst, sample size is a particularly troubling issue in MMA, and small samples cause instability. Win percent utilizes each fight once, and as a result, it can be an unstable metric for fighters that do not have many fights. Judging errors, for example, can cause large, unjust deviations in a fighter’s win percent during the early part of his or her career. Hence, intuitively, we see that only drawing from a handful of fight outcomes coupled with the judging volatility ingrained in those outcomes can make win percent a relatively unstable metric, especially early in a fighter’s career.\nThe xR% metric, on the other hand, is computed using each round as an observation. Thus, after only 4-5 fights, a fighter will generally have fought 10 or more rounds. Utilizing these additional observations from each fight allows xR% to essentially observe each fighter’s dominance (or lack thereof) in the octagon more often than win percent, which only considers each fight once. The metric generated from more observations should vary less over time because the stability of the metrics under consideration is generally correlated with sample size. Therefore, conceptually, we can see how xR% should be able to produce a more stable measure of fighter quality in fewer fights than win percent.\nIf the conceptual argument has not convinced you, let’s look at the degree to which these metrics actually change over a fighter’s career. This argument is a bit technical and in the weeds, so feel free to skip it if it does not interest you.\nUsing every UFC fight in 2011-2020, we first compute the difference in win percent and xR% from each fighter’s 1st-2nd UFC fight. Then, we compute the average of these differences for each metric and plot those two values on the figure below corresponding to a value of 2 on the horizontal axis (to represent the change occurring after each fighter’s 2nd UFC fight). Likewise, we take the difference in win percent and xR% from each fighter’s 2nd-3rd UFC fight, compute the average of those differences, and plot those points along the horizontal axis at a value of 3. We continue this process up to the 10th fight of each fighter’s UFC career. Finally, we repeat the whole process again, except we compute the standard deviation, instead of the average, of all differences.\nThe lines on the figure below essentially measure the magnitude of the variation in each metric (along the vertical axis) as the number of fights used to compute each metric increases (along the horizontal axis). Values measured on the vertical axis that are closer to 0 represent an increase in stability, or equivalently, less fight-to-fight variation in the metric. Eventually both metrics stabilize. That is, after many fights, a fighter’s win percent, for example, does not change much whether he or she wins or loses. Thus, we are more concerned with the stability of the metrics after the first few fights of a fighter’s career.\nWhile the actual values on the vertical axis do not need to be interpreted, what is important is how the lines relate to one another. We see that the xR% lines are essentially always closer to 0 than the win percent lines (especially after only a few fights), which means that the fight-by-fight change in xR% is generally less than that of win percent. Hence, xR% is mathematically the more stable metric, which aligns with the conceptual argument provided above.\n\n\n\n\n\n\n\n\n\n\n\nLimitations of xR\nWhile I have done my best to show the value of xR and xR% as fighter evaluation metrics, especially compared to convention metrics like win percent and finish percent, xR is far from perfect.\nFirst, xR does not account for the quality of an opponent. Therefore, it rewards high-quality fighters who resist the urge to climb the rankings quickly and instead dominate many unranked opponents.\nFurther, xR is computed using an imperfect machine learning algorithm that is developed using imperfect official UFC statistics and imperfect judging decisions. All machine learning models make errors. This model struggles the most when a fighter outperforms his or her opponent in the major statistical categories tracked but ends up taking more damage throughout the fight. Also, the official UFC statistics can be misleading, or even incorrect, at times, and lastly, the judges do make mistakes. Fortunately, the model still performs well even with all of these issues.\n\n\nExtensions of xR\nWhile I believe xR in its current state is incredibly valuable, I think there are a number of ways in which it can be improved or extended.\nAn opponent-adjusted xR that properly accounts for the quality of the opponent should noticeably improve the metric. If done correctly, a ranking system based on opponent-adjusted xR% could be useful.\nPerhaps most importantly, xR could be extended to other promotions if the round-level statistics and judging decisions were tracked and made publicly available. I believe this would greatly improve the value of xR and xR% in terms of both their informational and predictive value. Accounting for each fighter’s entire professional MMA career would, at the very least, increase the sample size and lead to better prospect identification and evaluation.\n\n\nConclusion\nQuantitative MMA analysis is challenging. Conventional fighter evaluation metrics like win percent and finish percent are easy to understand but leave a lot to be desired in terms of value.\nWhile certainly not perfect, xR and xR% provide noticeable improvements over these conventional metrics while not compromising on perhaps the most important aspect of an advanced metric: interpretability.\nThe figure below shows the cumulative xR% of the current top 5 men’s UFC pound-for-pound fighters. It is my hope that, after reading this post, everyone is able to fully understand what the lines on this figure represent.\n\n\n\n\n\n\n\n\n\nAs fighter evaluation metrics, xR and xR% are interpretable, informative, predictive, robust, and stable - which I believe makes them valuable tools that may be leveraged by the entire MMA community."
  },
  {
    "objectID": "posts/2022-01-05-visualizing-fighter-styles/index.html",
    "href": "posts/2022-01-05-visualizing-fighter-styles/index.html",
    "title": "Visualizing Fighter Styles",
    "section": "",
    "text": "Introduction\nLittle work has been done publicly to quantify fighter styles in the Ultimate Fighting Championship (UFC). Nevertheless, there are several distinct styles that are apparent to those who follow mixed martial arts (MMA), primarily due to the different disciplines encompassed within the sport.\nFor instance, UFC fans know that even though Giga Chikadze and Bryce Mitchell are both ranked Featherweights with 14 professional MMA wins who are undefeated in the UFC, their fighting styles are quite different. Chikadze’s success comes from elite kickboxing while Mitchell holds a black belt in Brazilian Jiu-Jitsu and largely relies on grappling.\nLike most sports, success in MMA can look very different for different athletes. Specialists may rely solely on either striking, wrestling, or grappling, but many in the UFC possess a well-rounded skill set across multiple disciplines. This post begins to explore UFC fighter styles quantitatively and serves as a simple introduction on how publicly available data can be leveraged to better understand stylistic differences between fighters.\n\n\nDistance %\nData from the official UFC statistics website partitions each round into time spent either (a) at distance, (b) in the clinch, or (c) on the ground. This post explores how often fighters spend at distance. That is,\n\\[\\begin{equation}\n\\text{Distance %} = \\frac{\\text{Time spent at distance}}{\\text{Total fight time}}\n\\end{equation}\\]\nAs seen in the figure below, Distance % varies across time and weight class. In general, UFC fighters have spent more time at distance over the latter half of the last decade. However, it is unclear if this trend is due to an evolution of the sport or a change in how the UFC selects prospects to sign.\nAs more young athletes are introduced to MMA earlier in life and have more time to train multiple disciplines, we might expect professional mixed martial artists to develop more competent striking and takedown defense, which could lead to more time spent at distance. On the other hand, to the extent that larger shares of the UFC fan base enjoy watching fights that predominantly take place on the feet, we might also expect the UFC to be more inclined to sign fighters with striking expertise over those who prefer grappling.\n\n\n\n\n\n\n\n\n\nThe figure below shows the career Distance % distribution for modern UFC fighters. With a median of 60.9%, the majority of fighters spend more than half of their careers at distance. If we partition the Distance % distribution into three equally-sized groups, as denoted by the dashed vertical lines in the figure below, we can place fighters into the following groups based on where their fights tend to take place:\n\nWrestling/Grappling Heavy = the 33% of fighters who spent the smallest % of their UFC career at distance (i.e. Distance % &lt; 52.8%), which means this group contains the 33% of fighters who spent the largest % of their career wrestling/grappling\nBalanced = the middle 33% of fighters in terms of UFC career Distance % (i.e. Distance % between 52.8% and 69.4%)\nDistance Striking Heavy = the 33% of fighters who spent the largest % of their UFC career at distance (i.e. Distance % &gt; 69.4%)\n\n\n\n\n\n\n\n\n\n\nPartitioning fighters by Distance % is meaningful because fighters with different backgrounds tend to prefer that their bouts take place at different places. For instance, those with a strong wrestling or Brazilian Jiu-Jitsu pedigree likely prefer to tie up opponents in the clinch and take the bout to the ground, which results in a lower Distance % than many of those with a strong kickboxing or Muay Thai background. While the groups derived from the Distance % distribution are certainly not perfect, they serve as rough approximations for the style of fight that each fighter prefers.\n\n\nControl Rate\nIn addition to grouping fighters based on how often they spend at distance, we can partition fighters based on how dominant they are in the clinch and on the ground. Since even the best strikers in MMA need some wrestling and grappling skills in order to defend takedowns and avoid submissions, forming groups based on a fighter’s ability to control opponents in the clinch and on the ground is meaningful.\nIn particular, we can use Control Rate to proxy for dominance in these situations. In simple terms, Control Rate is the percent of all clinch and ground time spent in a control position. That is,\n\\[\\begin{equation}\n\\text{Control Rate} = \\frac{\\text{Time spent in a clinch or ground control position}}{\\text{Total fight time spent in the clinch or on the ground}}\n\\end{equation}\\]\nPut another way,\n\\[\\begin{equation}\n\\text{Control Rate} = \\frac{\\text{Control time}}{\\text{Control time + Controlled time}}\n\\end{equation}\\]\nThe distribution of career Control Rate among modern UFC fighters is shown in the figure below. As we did above with Distance %, if we partition Control Rate into three groups of equal size, via the dashed vertical lines in the figure below, we can create the following groups based on a fighter’s ability to control opponents in the clinch and on the ground:\n\nNon-Dominant Wrestling/Grappling = the 33% of fighters with the lowest Control Rate (i.e. Control Rate &lt; 35.5%)\nBalanced = the middle 33% of fighters in terms of Control Rate (i.e. Control Rate between 35.5% and 62.0%)\nDominant Wrestling/Grappling = the 33% of fighters with the highest Control Rate (i.e. Control Rate &gt; 62.0%)\n\n\n\n\n\n\n\n\n\n\nControl Rate is an imperfect measure of clinch and ground dominance since, for instance, some fighters are still capable of submitting opponents with their backs against the ground in a non-control position. Nevertheless, Control Rate generally serves as a reasonable proxy for wrestling and grappling skill for most fighters.\n\n\nFighter Styles\nCombining Distance % and Control Rate allows us to place UFC fighters into broad, stylistic categories. The figure below illustrates the following four categories:\nA: Wrestling/Grappling Heavy with Dominant Wrestling/Grappling. These fighters tend to prefer fights involving a lot of wrestling and grappling, and they tend to be very successful when they are able to close the distance on their opponents and/or take them down to the ground.\nB: Distance Striking Heavy with Dominant Wrestling/Grappling. These fighters tend to prefer bouts spent predominantly at distance, and they spend little time in the clinch or on the ground because they generally possess either strong takedown defense or a strong wrestling/grappling pedigree such that their opponents would rather stand and strike with them than try to take them down.\nC: Wrestling/Grappling Heavy with Non-Dominant Wrestling/Grappling. These fighters tend to be unable to control where their fights take place. They spend a lot of time in the clinch and on the ground in non-control positions likely because of poor takedown defense and/or subpar grappling skills.\nD: Distance Striking Heavy with Non-Dominant Wrestling/Grappling. These fighters tend to prefer bouts that take place on the feet. Given their high Distance % coupled with their lack of wrestling/grappling success, these fighters likely possess and rely on a strong takedown defense to be successful and get into trouble when taken down by their opponents.\nThese categories are certainly imperfect, and there are likely many exceptions within each category. Further, fighters often change categories throughout their careers as their skills and tendencies (and that of their opponents) evolve. However, in general, these categories tend to reasonably depict the stylistic categories of many UFC fighters.\n\n\n\n\n\n\n\n\n\n\n\nStyles of Notable UFC Fighters\nThe figure below shows a few notable fighters from each of the aforementioned stylistic categories. In general, these categories describe these fighters’ styles well.\nThe fighters at the top left of the figure are known for their suffocating wrestling or grappling. Those at the top right typically prefer to stand and strike, and they have the capacity to keep the fight where they want with their strong wrestling or Brazilian Jiu-Jitsu pedigree. At the bottom right are fighters that are highly skilled at striking and can generally keep the fight at distance, but when they are taken down, they tend to struggle. Finally, at the bottom left are fighters that are controlled by their opponents often.\n\n\n\n\n\n\n\n\n\n\n\nUFC Men’s Pound-for-Pound Top 10\nThe styles of the current top 10 pound-for-pound fighters in the UFC are shown in the figure below.\nNote that even the best mixed martial artists in the world are not dominant in all areas of the sport. Israel Adesanya and Francis Ngannou, two current UFC champions, each have a Control Rate that is less than 15%. Their success comes from striking, and their precision and power at distance tends to offset any potential deficiencies they may have elsewhere.\nInterestingly, even though the UFC is trending toward more distance striking over the last few years, only 4 of the top 10 would be considered Distance Striking Heavy fighters. Hence, despite this trend, it still certainly pays to develop wrestling and grappling skills in modern MMA, which should come as no surprise.\n\n\n\n\n\n\n\n\n\n\n\nNext Steps\nThis post serves as a first, exploratory step toward quantitatively defining and visualizing fighter styles along two dimensions, Distance % and Control Rate. Be sure to connect with me on Twitter if you have any questions or comments, or if you would like to see how these types of figures evolve, as I will likely be sharing these on there going forward.\nThe relatively simple styles discussed throughout leave a lot to be desired, and there are several sensible paths forward that can increase the complexity and (hopefully) the value of the styles created. Some of the other potential metrics to consider in the future include distance striking pace, distance striking differential, takedown pace, takedown accuracy, and takedown defense. Each of these metrics attempts to quantify a fighter’s striking, wrestling, or grappling aptitude. Finally, an unsupervised learning, or clustering, approach may help identify more complicated and more informative styles across more dimensions than can be visualized on a plot."
  },
  {
    "objectID": "posts/2024-01-11-introducing-fightpicksim/index.html",
    "href": "posts/2024-01-11-introducing-fightpicksim/index.html",
    "title": "Introducing FightPickSim",
    "section": "",
    "text": "This post introduces FightPickSim, a new UFC DraftKings Daily Fantasy Sports (DFS) tool I built to perform fantasy point projections, event simulations, and lineup optimization. FightPickSim is an interactive website built using R and R Shiny that can be found here. This post documents how the tool works and how it has performed historically.\nFirst, for those unfamiliar with DFS, DraftKings hosts contests in which players construct a lineup of fighters for an upcoming UFC event, and each player’s objective is to build the lineup that scores the most fantasy points.\nEach lineup consists of six fighters, and each fighter has a different salary. When selecting a lineup, each DFS player is free to select any combination of fighters as long as the total salary for all six fighters does not exceed a fixed salary cap.\nThen, as the event plays out, fighters earn points for accumulating statistics, like significant strikes landed and control time, and for winning. Additional bonus points are awarded for finishes, and finishes in earlier rounds earn more points than finishes in later rounds.\nThe goal of FightPickSim is to help users construct lineups that outperform their peers by providing precise fantasy point projections, reliable projection uncertainty intervals, accurate optimal lineup forecasts, and well-calibrated optimal lineup probabilities."
  },
  {
    "objectID": "posts/2024-01-11-introducing-fightpicksim/index.html#precise-fantasy-point-projections",
    "href": "posts/2024-01-11-introducing-fightpicksim/index.html#precise-fantasy-point-projections",
    "title": "Introducing FightPickSim",
    "section": "Precise fantasy point projections",
    "text": "Precise fantasy point projections\nRather than generating a single fantasy point projection for each fighter, FightPickSim performs a Monte Carlo simulation of a UFC event using the user’s picks. That is, FightPickSim simulates the entire card 10,000 times and draws a projection for each fighter in each iteration of the simulation. This yields a distribution of projected fantasy points for each fighter, which unlocks deeper insight into the number of points each fighter may earn and allows us to quantify the uncertainty around these projections.\nUsing all 2023 UFC events as an evaluation period, the median absolute deviation between each fighter’s actual fantasy points and FightPickSim’s median projected fantasy points was 7.6, as seen in the figure below. Likewise, among winning fighters (i.e. the fighters we care the most about), the median absolute percentage difference between each fighter’s actual fantasy points and FightPickSim’s projected points was 9.6%. The figure below shows the distribution of differences between actual and projected fantasy points for all fighters.\nThis distribution is relatively centered around 0, which means projections overestimate actual performance nearly as often as they underestimate it. Given the variability in fighter performances in the UFC, I believe these performance metrics show that FightPickSim’s projections are strong."
  },
  {
    "objectID": "posts/2024-01-11-introducing-fightpicksim/index.html#reliable-projection-uncertainty-intervals",
    "href": "posts/2024-01-11-introducing-fightpicksim/index.html#reliable-projection-uncertainty-intervals",
    "title": "Introducing FightPickSim",
    "section": "Reliable projection uncertainty intervals",
    "text": "Reliable projection uncertainty intervals\nFightPickSim leverages the distribution of projections generated in the Monte Carlo simulation to construct uncertainty intervals around each fighter’s projection. That is, based on the user’s picks, each fighter is given an interval such that there is, say, an 80% chance that the fighter’s actual fantasy points land within that interval.\nIn the FightPickSim tool, users can adjust the coverage of the uncertainty interval, so if a user wants an interval that has a 90% chance of containing the fighter’s actual fantasy points, that may be selected. However, there is no free lunch – an interval that has a 90% chance of containing a fighter’s actual fantasy points will be wider than an interval with an 80% chance. As the likelihood of containing the actual value increases, the width of the interval increases as well, so there is a tradeoff between coverage and precision.\nThe most important aspect of FightPickSim’s uncertainty intervals is that they are reliable and well calibrated. That is, among all uncertainty intervals that claim to contain a fighter’s actual fantasy points with 80% probability, we see in the figure below that ~80.5% of these intervals contained the actual value. The same holds for intervals with different expected coverage. Hence, users can trust the coverage claimed by these intervals."
  },
  {
    "objectID": "posts/2024-01-11-introducing-fightpicksim/index.html#accurate-optimal-lineup-forecasts",
    "href": "posts/2024-01-11-introducing-fightpicksim/index.html#accurate-optimal-lineup-forecasts",
    "title": "Introducing FightPickSim",
    "section": "Accurate optimal lineup forecasts",
    "text": "Accurate optimal lineup forecasts\nIn DFS, the optimal lineup is the set of six fighters who scored the most total fantasy points with a total salary that does not exceed the salary cap. Put more simply, the optimal lineup is the best possible lineup a DFS player could select. Since there are so many possible combinations of lineups, most lineups that win money in DFS are suboptimal lineups, but the optimal lineup is still what every DFS player seeks.\nFightPickSim leverages a user’s picks and the subsequent fantasy point projections to forecast the optimal lineup. Methodologically, this is a relatively straightforward optimization problem where the projections are maximized subject to the constraints of having to select six fighters with a total salary that does not exceed the salary cap.\nIn practice, FightPickSim reliably forecasts optimal lineups. The figure below shows the frequency in which each number of possible optimal lineup fighters was correctly predicted for a UFC event. That is, all six optimal lineup fighters were correctly predicted by FightPickSim in 16.3% of 2023 UFC events, so if a user had input perfect picks for those events, FightPickSim would have provided the full optimal lineup. For nearly half of the 2023 UFC events, FightPickSim was able to forecast at least five of the six optimal lineup fighters, and it never correctly forecasted fewer than three. Therefore, users that bring correct picks to FightPickSim can expect to build lineups with optimal lineup fighters."
  },
  {
    "objectID": "posts/2024-01-11-introducing-fightpicksim/index.html#well-calibrated-optimal-lineup-probabilities",
    "href": "posts/2024-01-11-introducing-fightpicksim/index.html#well-calibrated-optimal-lineup-probabilities",
    "title": "Introducing FightPickSim",
    "section": "Well-calibrated optimal lineup probabilities",
    "text": "Well-calibrated optimal lineup probabilities\nThe aforementioned optimal lineup forecasts consist of binary predictions denoting whether or not each fighter will land in the optimal lineup, but perhaps more importantly, FightPickSim is able to provide a well-calibrated probability that each fighter will appear in the optimal lineup based on a user’s picks. That is, in the FightPickSim Monte Carlo simulation, 10,000 optimal lineups are computed, and the percent of optimal lineups that include a given fighter, known as optimal lineup percent, is calculated.\nThe figure below shows that optimal lineup percent is well calibrated. For instance, among all fighters with an optimal lineup percent between 80-90%, 87% appear in the actual optimal lineup. A similar relationship exists for every other bin between 0-100%, which shows that optimal lineup percent can be treated as a reliable probability that a fighter will appear in the true optimal lineup."
  },
  {
    "objectID": "posts/2025-03-02-introducing-strike-accuracy-over-expected/index.html",
    "href": "posts/2025-03-02-introducing-strike-accuracy-over-expected/index.html",
    "title": "Introducing Strike Accuracy Over Expected (SAOE)",
    "section": "",
    "text": "Introduction\nThe Ultimate Fighting Championship (UFC) recently introduced a new strike accuracy-related metric for broadcasts. In short, certain types of strikes (e.g. power punches to the body from a mounted position) are easier to land than others (e.g. head kicks from distance). Since these different types of strikes land at significantly different rates, a fighter’s strike accuracy can be more a function of striking tendencies than an actual, informative measure of a fighter’s ability to land strikes.\nTo solve this limitation of strike accuracy as a metric, the UFC computes an expected strike accuracy based on both (a) the types of strikes that each fighter throws and (b) the rate at which each type of strike has landed historically across all fighters. Then, the difference between a fighter’s observed and expected strike accuracy is computed to serve as a more meaningful measure of accuracy.\nThis blog post utilizes this concept to formally introduce Strike Accuracy Over Expected (SAOE), a new metric that aims to quantify a fighter’s striking precision in a manner that improves upon the traditional strike accuracy metric. The details are provided below in this post, but put simply, SAOE has three desirable properties:\n\nSAOE is easily interpreted - it is interpreted as the percentage point difference between a fighter’s observed and expected strike accuracy.\nSAOE offers new insights - it contains a frame of reference for strike accuracy against which to compare to a fighter’s performance and wraps that up into a single, composite metric that quantifies striking precision.\nSAOE facilitates meaningful comparisons between fighters with different styles - it is correlated with strike accuracy but uncorrelated with striking tendencies.\n\nAs a final note, the concept of SAOE is grounded in advanced analytics work from other sports. For instance, within the last couple years, National Football League (NFL) analysts have shown that a quarterback’s raw completion percentage is not strongly correlated with performance. In fact, some lower-quality quarterbacks have high completion percentages because they often throw short, safe passes. To improve upon completion percentage as a metric, Completion Percentage Over Expected (CPOE) was developed. CPOE calculates the probability that a pass will be completed based on a number of factors (e.g. how far the ball travels in the air, the down and yards to go for a first down, etc.) and then computes the difference between a quarterback’s observed and expected completion percentage. Completing a high percentage of safe throws is not equivalent to completing the same percentage of challenging throws, and since CPOE is able to distinguish between the two, it has been shown to be a much more meaningful measure of quarterback performance.\nWith this blog post, we now have an advanced metric that is similar in concept and function to better quantify striking precision in the UFC.\n\n\nMotivation: why strike accuracy is limited\nStrike accuracy, defined as the number of significant strikes a fighter lands divided by the number attempted, is easy to understand but is often not informative as a single measure of striking ability. Consider the figure below, which shows that distance strike accuracy is significantly lower than clinch and ground accuracy. Hence, an average fighter who only throws strikes from distance will have a lower strike accuracy than an average fighter who only throws strikes from the clinch and on the ground, and this difference would be purely due to striking tendencies rather than skill differences.\n\n\n\n\n\n\n\n\n\nTo further illustrate the point, the most common comparative use case of strike accuracy is (presumably) to determine which fighter is the more precise overall striker, and as such, strike accuracy as a metric can be problematic. The figure below shows that strike accuracy is negatively correlated with a fighter’s percent of significant strikes thrown at distance. Further, strike accuracy is positively correlated with a fighter’s percent of significant strikes thrown both from the clinch and on the ground. Thus, fighters who throw more strikes from distance tend to have lower strike accuracy, so when a kickboxer fights a grappler, comparing strike accuracy as a proxy for overall striking ability is likely to show the opposite of what is actually true.\n\nDistanceClinchGround\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, the table below shows the top 10 UFC fighters with the highest strike accuracy, among fighters with 300+ significant strike attempts and 1+ bouts since 2022. Many on this list are not necessarily considered elite strikers, and most throw a relatively small percent of strikes from distance, which indicates their strike accuracy is largely driven by striking tendencies rather than precision. As such, this top 10 list is not particularly relevant.\n\n\n\nUFC Career Strike Accuracy Top 10 (among fighters with 300+ significant strike attempts and at least 1 bout since 2022)\n\n\nFighter\nStrike accuracy\nDistance % of strike attempts\nSignificant strikes attempts\n\n\n\n\nAnthony Hernandez\n63.4%\n56.3%\n748\n\n\nAlex Pereira\n63.1%\n86.9%\n921\n\n\nChristian Leroy Duncan\n62.5%\n79.6%\n363\n\n\nShara Magomedov\n62.4%\n86.7%\n633\n\n\nChidi Njokuani\n62.0%\n61.4%\n495\n\n\nTatiana Suarez\n61.7%\n47.7%\n472\n\n\nSean O'Malley\n61.5%\n95.8%\n1,645\n\n\nCiryl Gane\n61.3%\n92.3%\n1,467\n\n\nGunnar Nelson\n61.1%\n66.0%\n453\n\n\nPhil Hawes\n60.7%\n79.9%\n512\n\n\n\n\n\n\n\nTherefore, strike accuracy is limited in its ability to depict anything meaningful when (a) considering one fighter at a time, (b) comparing two fighters, and (c) attempting to rank fighters. Enter SAOE, a new and improved measure for overall striking precision.\n\n\nCalculating Strike Accuracy Over Expected (SAOE)\nSAOE is interpreted as the percentage point difference between observed and expected strike accuracy based on the types of strikes thrown. Positive numbers indicate fighters are more accurate than we would expect given their strike attempt distribution, and thus, elite strikers often rank highly in SAOE.\nUnderstanding SAOE is as simple as comprehending the paragraph above. Now, the rest of this section gets mildly technical to show the computational details of the SAOE metric, so here is your warning if that is not of interest - you should be able to safely skip to the next section that showcases the importance of SAOE. For everyone else, I attempt to keep the forthcoming notation light and as readable as possible.\nMathematically, SAOE is calculated as follows:\n\\[\nSAOE = \\text{Significant strike accuracy} - \\text{Expected significant strike accuracy}\n\\]\nThe only complexity underlying SAOE is then how to compute expected strike accuracy. The current version of SAOE separates distance, clinch, and ground strikes, and the expected accuracy is calculated for each bout using the corresponding accuracy of the given weight class from the prior calendar year. As an example, the expected distance strike accuracy for a Lightweight bout in 2025 is the total distance strike accuracy from all distance strikes thrown in Lightweight bouts in 2024. Expected clinch and ground strike accuracy is computed analogously. Also, for all Catchweight bouts (since there are so few) and for all fights in the debut year of a weight class, the expected accuracy metrics are calculated using all fights from the prior calendar year.\nWith this methodology, the updated formula for SAOE for a given fighter \\(f\\) is:\n\\[\\begin{aligned}\n\nSAOE_f &= \\text{Significant strike accuracy}_f - \\text{Expected significant strike accuracy}_f \\\\\n\n&= \\frac{\\text{Significant strikes landed}_f}{\\text{Significant strikes attempted}_f} - \\frac{\\text{Expected significant strikes landed}_f}{\\text{Significant strikes attempted}_f} \\\\\n\n&= \\frac{\\text{Significant strikes landed}_f - \\text{Expected significant strikes landed}_f}{\\text{Significant strikes attempted}_f}\n\n\\end{aligned}\\]\nNow, let \\(B_f\\) be the set of UFC bouts for fighter \\(f\\), and let the prior year’s distance/clinch/ground strike accuracy be for the associated weight class for bout \\(b\\). Then, the formula for the expected number of significant strikes landed for the entire UFC career of fighter \\(f\\) is:\n\\[\\begin{array}{l}\n\n\\text{Expected significant strikes landed}_f = \\\\\n\n\\sum_{b \\in B_f} \\text{Expected distance strikes landed}_{f,b} + \\text{Expected clinch strikes landed}_{f,b} \\\\\n+ \\text{Expected ground strikes landed}_{f,b} = \\\\\n\n\\sum_{b \\in B_f} \\text{Distance significant strike attempts}_{f,b} * \\text{prior year distance strike accuracy}_b \\\\\n+ \\text{Clinch significant strike attempts}_{f,b} * \\text{prior year clinch strike accuracy}_b \\\\\n+ \\text{Ground significant strike attempts}_{f,b} * \\text{prior year ground strike accuracy}_b\n\n\\end{array}\\]\nFor those who do not follow the notation, the expected number of significant strikes landed for a given fighter in a single bout is the sum of the expected number of distance, clinch, and ground significant strikes landed. Next, the expected number of distance strikes landed is the number of distance significant strike attempts times the distance strike accuracy for the corresponding weight class in the prior year (and so on for expected clinch and ground strikes). Then, summing those values across all bouts in the given fighter’s career yields the expected number of significant strikes landed, which can be plugged into the equation above for \\(SAOE_f\\).\n\n\nHow SAOE improves upon strike accuracy\nThe objective of this section is to illustrate how SAOE improves upon strike accuracy as a more informative composite measure of striking precision while maintaining interpretability.\nTo start, consider Sean O’Malley’s strike accuracy and SAOE in the table below.\n\n\n\nSean O'Malley UFC Career Striking Statistics (as of March 01, 2025)\n\n\nStrike Accuracy\nSAOE\nDistance % of Strike Attempts\n\n\n\n\n61.5%\n+18.5%\n95.8%\n\n\n\n\n\n\n\nStrike accuracy alone does not provide any context, meaning it is unclear if O’Malley’s accuracy is high or low because there is no point of reference. SAOE, on the other hand, contains that context and depicts how much more accurate O’Malley is than the aggregate of his peers. In this case, O’Malley’s SAOE of +18.5% indicates that his strike accuracy is 18.5 percentage points higher than expected; hence, his expected strike accuracy based on the distribution of distance, clinch, and ground strikes he throws is: 61.5% - 18.5% = 43.0%.\nComparing strike accuracy between fighters can further exacerbate the issue, as seen in the table below. Jailton Almeida has a noticeably higher strike accuracy than Ciryl Gane. However, that difference in strike accuracy is largely driven by striking tendencies - Almeida throws nearly all his strikes from the clinch or ground while Gane strikes almost exclusively from distance. When accounting for the inherent differences in distance, clinch, and ground strikes, SAOE shows that Gane is clearly the more precise striker, as we would expect.\n\n\n\nUFC Career Striking Statistics (as of March 01, 2025)\n\n\nFighter\nStrike Accuracy\nSAOE\nDistance % of Strike Attempts\n\n\n\n\nJailton Almeida\n66.8%\n-2.9%\n13.6%\n\n\nCiryl Gane\n61.3%\n+13.7%\n92.3%\n\n\n\n\n\n\n\nThe table below shows Pearson correlation coefficients that describe the strength and direction of the linear relationships between striking metric (i.e. strike accuracy and SAOE) and striking tendencies (i.e. percent of strikes thrown at distance, in the clinch, or on the ground). Pearson correlation coefficients range from -1 to 1 such that positive numbers indicate a positive linear relationship (and vice versa for negative numbers) and 0 indicates no linear relationship.\nAs we can see, strike accuracy is moderately correlated with striking tendencies, but SAOE is effectively uncorrelated with the distribution of a fighter’s strike attempts. This property of SAOE is desirable because, unlike strike accuracy, it allows for meaningful comparisons between fighters across striking styles and tendencies. Put another way, a fighter’s strike accuracy can be artificially inflated by being an average grounder striker who only throws ground strikes. However, that is not possible with SAOE - this hypothetical fighter would have to be an above average ground striker to have a positive SAOE.\n\n\n\nPearson Correlation Coefficients (among fighters with 300+ significant strike attempts and at least 1 bout since 2022)\n\n\n\nStrike Accuracy\nSAOE\n\n\n\n\nDistance % of strike attempts\n-0.460\n-0.096\n\n\nClinch % of strike attempts\n0.332\n0.138\n\n\nGround % of strike attempts\n0.361\n0.029\n\n\n\n\n\n\n\nFinally, the table below shows the top 10 fighters with the highest UFC career SAOE. Unlike the top 10 in strike accuracy shown in a prior table, this table features almost exclusively elite strikers, which is a positive sign for the SAOE metric’s ability to meaningfully quantify striking precision.\n\n\n\nUFC Career SAOE Top 10 (among fighters with 300+ significant strike attempts and at least 1 bout since 2022)\n\n\nFighter\nSAOE\nStrike accuracy\nDistance % of strike attempts\nSignificant strikes attempts\n\n\n\n\nSean O'Malley\n+ 18.5%\n61.5%\n95.8%\n1,645\n\n\nChris Gutierrez\n+ 16.5%\n59.1%\n95.7%\n1,384\n\n\nJustin Gaethje\n+ 15.2%\n59.2%\n91.0%\n1,628\n\n\nAlex Pereira\n+ 14.4%\n63.1%\n86.9%\n921\n\n\nCiryl Gane\n+ 13.7%\n61.3%\n92.3%\n1,467\n\n\nPaulo Costa\n+ 13.0%\n58.3%\n91.5%\n1,337\n\n\nShara Magomedov\n+ 12.8%\n62.4%\n86.7%\n633\n\n\nGabriel Santos\n+ 12.7%\n60.6%\n82.9%\n368\n\n\nGunnar Nelson\n+ 12.6%\n61.1%\n66.0%\n453\n\n\nJon Jones\n+ 12.3%\n58.9%\n72.2%\n2,655\n\n\n\n\n\n\n\n\n\nComponents of SAOE\nSAOE serves as a composite measure of striking precision across all strikes. However, breaking SAOE into its distance, clinch, and ground striking components is also informative. The formula for, say, Distance SAOE is the same as SAOE, minus the clinch and ground strikes. Hence, Distance SAOE is interpreted as the percentage point difference between observed and expected distance strike accuracy. Clinch SAOE and Ground SAOE are interpreted similarly.\nThe table below shows the UFC’s top 10 in SAOE alongside each fighter’s Distance, Clinch, and Ground SAOE. We can see that Sean O’Malley predominantly strikes from distance, but his clinch and ground striking precision has been strong so far. However, while Chris Gutierrez also throws the majority of his strikes from distance, the precision of his clinch and ground striking has been lacking. Thus, breaking SAOE into its components can highlight the different strengths and weaknesses of a fighter’s striking game.\n\n\n\n\n\n\n\n\n\n\n\nLimitations of SAOE\nWhile SAOE offers a clear improvement over strike accuracy and has many desirable properties, this version of SAOE is based on publicly available data and thus far from perfect. For instance, rather than only partitioning strikes based on whether they were thrown from distance, in the clinch, or on the ground, we would also preferably distinguish between the strike type (i.e. punch, kick, knee, elbow) and the target (i.e. opponent’s head, body, or legs). All of these different attributes of a strike are presumably associated with an inherently different accuracy that SAOE would ideally account for, but unfortunately, current publicly available data does not provide that level of granularity.\n\n\nNext steps\nThe natural follow on to SAOE is Strike Defense Over Expected (SDOE). Offensive striking only tells half the story of striking, so exploring how strike defense (defined as the number of significant strikes a fighter’s opponent misses divided by the number of significant strikes the opponent attempts) compares to an SDOE metric that accounts for the distribution of strike attempts faced at distance, in the clinch, or on the ground - alongside the associated expected strike defense of each - will hopefully be similarly valuable.\nFinally, once both SAOE and SDOE are developed as composite offensive and defensive striking metrics, respectively, more work can be done to attempt to combine these metrics into a single, unified advanced striking metric that considers both offensive and defensive striking prowess relative to expectation. Stay tuned for more work on this front - the best way to do so is to follow me on Twitter at @NateLatshaw."
  }
]