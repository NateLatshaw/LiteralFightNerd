[
  {
    "path": "posts/2021-03-02-introducing-expected-rounds-xr/",
    "title": "Introducing Expected Rounds (xR)",
    "description": "A new advanced fighter evaluation metric that is interpretable, informative, predictive, robust, and stable",
    "author": [
      {
        "name": "Nate Latshaw",
        "url": {}
      }
    ],
    "date": "2021-03-02",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nCurrent quantitative fighter evaluation limitations\r\nPushing the envelope with xR\r\nWhy you should care about xR\r\n\r\nMethodology\r\nxR is informative\r\nxR is predictive\r\nxR is robust\r\nxR is stable\r\nLimitations of xR\r\nExtensions of xR\r\nConclusion\r\n\r\nIntroduction\r\nCurrent quantitative fighter evaluation limitations\r\nQuantitative mixed martial arts (MMA) analysis features two common challenges: dealing with small samples sizes and capturing the nuance that is inherent to the sport. Mainstream fighter evaluation metrics do not properly address these challenges.\r\nIn general, fighters do not have many professional MMA fights, and among their limited number of fights, the Ultimate Fighting Championship (UFC) is really the only MMA promotion that publicly tracks striking and grappling statistics from within each fight (though there are some exceptions). Hence, the amount of data that can be collected on each professional UFC fighter is limited, which makes quantitative analysis difficult.\r\nFurther, MMA is a sport that features many different fighting styles and techniques that are difficult to quantify. Fights can end at any moment via knockout or submission, so there are a number of paths to victory for fighters that possess expertise in multiple MMA disciplines. However, finishing ability is not the only signal of dominance in MMA. Proper fighter evaluation metrics should not only rely on finishing ability but should also capture other forms of dominance inside the octagon.\r\nCurrently, fighters are frequently evaluated on their win percent (number of fights won divided by total number of fights) and finish percent (number of fights won via knockout or submission divided by number of fights won). However, both of these metrics are limited. In addition to small sample size issues, win percent fails to differentiate between close wins, dominant wins, and judging blunders. Finish percent measures a fighter’s ability to finish a fight, but as a broader measure of fighter dominance, it does not account for dominant wins by decision, which are arguably just as impressive as finishes.\r\nPushing the envelope with xR\r\nEnter expected rounds (xR) and expected round percent (xR%), new advanced metrics that aim to address the sample size and nuance issues that typically plague other fighter evaluation measures. There are many reasons why I believe the MMA community could benefit from these metrics.\r\nFirst and foremost, as an advanced metric, xR is interpretable and easy to understand:\r\nxR is the number of rounds a fighter would expect to have won, on average, given his or her round-by-round performances.\r\nThat’s it. Anyone who can understand that is capable of adopting this metric. The accompanying metric xR% is then just as straightforward:\r\nxR% is the percent of rounds a fighter would expect to have won, on average, given his or her round-by-round performances.\r\nThe rest of this post will cover the methodological details of these metrics and then step through a number of reasons why MMA audiences of all types should care about xR and xR%. However, I want it to be stated clearly up front that these are advanced metrics that are approachable for everyone. If the technical details of these metrics do not interest you, feel free to skip over that section. You do not need to understand precisely how these metrics are computed in order to understand what they seek to measure and how they improve on current mainstream fighter evaluation metrics like win percent and finish percent.\r\nWhy you should care about xR\r\nBefore jumping into the methodology, below I’ve listed the five most significant reasons why I believe xR and xR% should be embraced by the MMA community. The first reason, simplicity, has already been covered. It is my job in this post to convince readers of the remaining four reasons.\r\nxR and xR% are easy to understand and interpret\r\nxR% is more informative than win percent and finish percent\r\nxR% is more predictive than win percent and finish percent\r\nxR% is more robust to judging blunders than win percent\r\nxR% is more stable than win percent\r\nMethodology\r\nThe xR metric is an extension of a machine learning algorithm I developed in a previous blog post. That algorithm uses official UFC round-level striking and grappling statistics to predict judges’ scores by round. The model used to create xR is trained on 4,399 UFC fights that all ended in a decision by the judges across 2011-2020. As demonstrated in my prior post, the model is able to predict round scores with a high degree of accuracy and generate well-calibrated probabilities for each possible round score. That is, for each round in the UFC, we use the model to recover the probability that the judges will score that round 10-9, 10-8, 9-10, or 8-10. Then, using these round score probabilities, we compute the probability of each fighter winning that round.\r\nFor each round that does not end via knockout or submission, xR is simply the probability that a particular fighter won the round. Hence, xR treats each round as a single point that is up for grabs and uses round win probabilities to partition that point between the two fighters. Then, for each round that ends in a knockout or submission, the winning fighter’s xR for that round is 1 and the losing fighter’s xR for that round is 0. The equation below defines xR for a given fighter as a piece-wise function.\r\nxR for a given fighter and round: \\[\\begin{equation}\r\nxR = \r\n\\begin{cases} \r\n0 & \\text{if fighter loses by knockout/submission} \\\\\r\n\\text{round win probability} & \\text{if round goes the distance} \\\\\r\n1 & \\text{if fighter wins by knockout/submission}\r\n\\end{cases}\r\n\\end{equation}\\]\r\nNotice that xR is computed by round, so for instance, a fighter who wins a fight via a second round submission will likely not capture all available xR for that fight. Instead, the first round’s xR will be partitioned according to each fighter’s round win probability, and then all of the second round’s xR will be given to the fighter who won by submission.\r\nMore concretely, consider Table 1 below of a hypothetical fight between Fighter A and Fighter B where Fighter A lands fewer strikes in the first round than his opponent but then wins by submission in the second. Here we see that xR is computed for each round independently of all other rounds. Then, aggregating xR up to the fight level yields the number of rounds each fighter could expect to win, on average, given their performances in each round.\r\nEven though Fighter B landed more strikes in the first round, there is uncertainty in how the judges would have scored this round, so Fighter A still gets some credit for that round. However, since Fighter A earned a submission in the second round, the entire round’s worth of xR goes to him. Thus, on average, Fighter A could expect to win 1.4 rounds if this exact fight was fought many times - sometimes he would lose the first round on the judges’ scorecard but other times he would win it. The xR metric attempts to capture the uncertainty in how rounds are scored by the judges, which separates it from traditional metrics like win percent and finish percent.\r\nFinally, we see below that xR% is computed by adding each fighter’s xR across rounds and then dividing by the number of rounds fought. At the fight level, this tells us what percent of rounds each fighter could expect to win given their round-level performances. Computing xR% over a fighter’s career would then describe how dominant that fighter has been by round, which again separates xR from win percent and finish percent.\r\nIn the hypothetical example below, if this was Fighter A’s first fight, his win and finish percents would be 100%, but his xR would only be 70%, which would better reflect his body of work since it accounts for the first round where he likely lost.\r\n\r\n\r\nTable 1: xR for a hypothetical fight\r\n\r\n\r\nFighter\r\n\r\n\r\nRound 1 xR\r\n\r\n\r\nRound 2 xR\r\n\r\n\r\nFight xR\r\n\r\n\r\nFight xR%\r\n\r\n\r\nA\r\n\r\n\r\n0.4\r\n\r\n\r\n1.0\r\n\r\n\r\n0.4 + 1.0 = 1.4\r\n\r\n\r\n1.4 / 2 = 0.7 = 70%\r\n\r\n\r\nB\r\n\r\n\r\n0.6\r\n\r\n\r\n0.0\r\n\r\n\r\n0.6 + 0.0 = 0.6\r\n\r\n\r\n0.6 / 2 = 0.3 = 30%\r\n\r\n\r\nNote: \r\n\r\n\r\n -In this example, Fighter A wins in the second round via submission.\r\n\r\n\r\nAgain, if you are interested in understanding the technical details of how each fighter’s round win probability is computed, feel free to check out my previous blog post that provides a detailed overview of the algorithm and its performance.\r\nxR is informative\r\nThe xR and xR% metrics are more informative fighter evaluation tools than mainstream metrics (like number of wins, number of finishes, win percent, and finish percent) because they value the characteristics of a fight that fighters strive to achieve. That is, xR rewards fighters for both dominance and finishing ability, and it can distinguish between fighters who just barely outperform their opponents and fighters who completely dominate their opponents.\r\nEarning a finish is not the only way to signal dominance in the octagon, so finish percent clearly does not tell the whole story. Further, win percent does not account for the difference between a close split decision win and a clear unanimous decision win, but everyone who watches these fights can often immediately tell the difference between the two.\r\nSince xR uses well-calibrated round win probabilities, a fighter’s xR and xR% for a close split decision is much lower, on average, than that of a dominant win. Table 2 below shows the average xR% earned by the winning fighter based on the method of victory. Not only is there a large difference between split and unanimous decisions, which further suggests that xR is being awarded appropriately, but we see that submissions and knockouts tend to result in even higher xR%. Hence, xR rewards both dominance and finishing ability in the octagon, unlike traditional fighter evaluation metrics.\r\n\r\n\r\nTable 2: Average earned fight xR% among winners\r\n\r\n\r\nMethod of Victory\r\n\r\n\r\nAverage Winner’s Earned xR%\r\n\r\n\r\nSplit Decision\r\n\r\n\r\n59.6%\r\n\r\n\r\nUnanimous Decision\r\n\r\n\r\n78.5%\r\n\r\n\r\nSubmission\r\n\r\n\r\n88.8%\r\n\r\n\r\nKnockout\r\n\r\n\r\n90.1%\r\n\r\n\r\nNote: \r\n\r\n\r\n -This table includes all UFC fights between 2011-2020.\r\n\r\n\r\nAs a more concrete example, Table 3 below shows the xR breakdown for the UFC 245 main event between Kamaru Usman and Colby Covington. The fight was close heading into the fifth round where Usman won by knockout. Conventional metrics like win percent and finish percent assign this fight as a 1 for Usman and a 0 for Covington. However, those metrics leave a lot to be desired in terms of descriptive value, which is exactly why we turn to xR.\r\nAccording to the algorithm, Covington had a 68.9% probability of winning the first round on the judges’ scorecard, so his xR for this round is 0.689. No matter what happens in subsequent rounds, Covington retains this xR for that round.\r\n\r\n\r\nTable 3: xR of UFC 245 main event\r\n\r\n\r\nRound\r\n\r\n\r\nUsman xR\r\n\r\n\r\nCovington xR\r\n\r\n\r\n1\r\n\r\n\r\n0.311\r\n\r\n\r\n0.689\r\n\r\n\r\n2\r\n\r\n\r\n0.347\r\n\r\n\r\n0.653\r\n\r\n\r\n3\r\n\r\n\r\n0.975\r\n\r\n\r\n0.025\r\n\r\n\r\n4\r\n\r\n\r\n0.313\r\n\r\n\r\n0.687\r\n\r\n\r\n5\r\n\r\n\r\n1.000\r\n\r\n\r\n0.000\r\n\r\n\r\nThe aggregate xR and xR% for the fight are displayed in Table 4 below. We see that Usman walked away with the majority of the available xR after earning the knockout, but Covington also leaves with some xR for his efforts.\r\n\r\n\r\nTable 4: Total xR and xR%\r\n\r\n\r\nFighter\r\n\r\n\r\nxR\r\n\r\n\r\nxR%\r\n\r\n\r\nKamaru Usman\r\n\r\n\r\n2.95\r\n\r\n\r\n58.9%\r\n\r\n\r\nColby Covington\r\n\r\n\r\n2.05\r\n\r\n\r\n41.1%\r\n\r\n\r\nNote: \r\n\r\n\r\n -This table presents xR and xR% at the fight level.\r\n\r\n\r\nFinally, notice how tight this fight was and how xR% reflected that but win percent and finish percent did not. The amount of information lost using conventional metrics is significant. Now imagine how wide that information gap could grow when you consider an entire fighter’s career. Relative to win percent and finish percent, xR% paints a much clearer picture of a fighter’s body of work across his or her career.\r\nxR is predictive\r\nTo justify my claim that xR% is more predictive than win percent and finish percent, I calculate each UFC fighter’s cumulative xR%, win percent, and finish percent prior to each fight in his or her UFC career. Then, for xR%, I predict that the fighter with the higher xR% (from UFC fights) will win. For win percent, I predict that the fighter with the higher UFC win percent will win (and so on). Hence, each prediction is made using only information from each fighter’s prior UFC fights.\r\nNote that predictions cannot be made for every UFC fight. If either fighter is making a UFC debut, then we do not have these metrics available for the debut fighter, so no prediction is made. Likewise, if the two fighters in a given fight have the same win percent, for instance, then no prediction is made based on win percent, but xR% and finish percent predictions will still be made (assuming there are no ties among these metrics).\r\nWe attempt to make predictions for all 4,399 UFC fights in 2011-2020. Table 5 below shows the results. We see that xR% makes more predictions than win percent and finish percent (as a result of fewer ties in xR%) and correctly predicts a higher share of fights in nearly every single year under consideration. It is significant that xR% is able to both make more predictions and predict better. It is generally easier to find more predictive success by making predictions on a narrower subset of the data, but the promise of xR% does not rely on making fewer predictions.\r\nI am not claiming that xR% will get you rich in the betting markets. However, it is clear that xR% is a fighter evaluation metric that is more predictive of a given fight outcome than win percent and finish percent, and this has been true for essentially the entirety of the past decade.\r\n\r\n\r\nTable 5: Predicting UFC fights with xR%, win %, and finish %\r\n\r\n\r\nYear\r\n\r\n\r\nxR% predictions\r\n\r\n\r\nxR% accuracy\r\n\r\n\r\nWin % predictions\r\n\r\n\r\nWin % accuracy\r\n\r\n\r\nFinish % predictions\r\n\r\n\r\nFinish % accuracy\r\n\r\n\r\n2011\r\n\r\n\r\n206\r\n\r\n\r\n53.9%\r\n\r\n\r\n173\r\n\r\n\r\n53.8%\r\n\r\n\r\n150\r\n\r\n\r\n49.3%\r\n\r\n\r\n2012\r\n\r\n\r\n252\r\n\r\n\r\n55.6%\r\n\r\n\r\n213\r\n\r\n\r\n53.5%\r\n\r\n\r\n170\r\n\r\n\r\n42.9%\r\n\r\n\r\n2013\r\n\r\n\r\n275\r\n\r\n\r\n56.4%\r\n\r\n\r\n234\r\n\r\n\r\n56.8%\r\n\r\n\r\n195\r\n\r\n\r\n49.2%\r\n\r\n\r\n2014\r\n\r\n\r\n333\r\n\r\n\r\n58.0%\r\n\r\n\r\n274\r\n\r\n\r\n56.6%\r\n\r\n\r\n236\r\n\r\n\r\n50.8%\r\n\r\n\r\n2015\r\n\r\n\r\n391\r\n\r\n\r\n55.8%\r\n\r\n\r\n324\r\n\r\n\r\n52.2%\r\n\r\n\r\n273\r\n\r\n\r\n53.1%\r\n\r\n\r\n2016\r\n\r\n\r\n386\r\n\r\n\r\n58.3%\r\n\r\n\r\n340\r\n\r\n\r\n58.5%\r\n\r\n\r\n293\r\n\r\n\r\n51.9%\r\n\r\n\r\n2017\r\n\r\n\r\n353\r\n\r\n\r\n56.7%\r\n\r\n\r\n310\r\n\r\n\r\n52.6%\r\n\r\n\r\n274\r\n\r\n\r\n44.5%\r\n\r\n\r\n2018\r\n\r\n\r\n369\r\n\r\n\r\n55.6%\r\n\r\n\r\n330\r\n\r\n\r\n53.6%\r\n\r\n\r\n282\r\n\r\n\r\n47.9%\r\n\r\n\r\n2019\r\n\r\n\r\n393\r\n\r\n\r\n55.7%\r\n\r\n\r\n350\r\n\r\n\r\n52.6%\r\n\r\n\r\n286\r\n\r\n\r\n54.2%\r\n\r\n\r\n2020\r\n\r\n\r\n351\r\n\r\n\r\n55.0%\r\n\r\n\r\n325\r\n\r\n\r\n52.9%\r\n\r\n\r\n249\r\n\r\n\r\n49.4%\r\n\r\n\r\nTotal\r\n\r\n\r\n3,309\r\n\r\n\r\n56.2%\r\n\r\n\r\n2,873\r\n\r\n\r\n54.3%\r\n\r\n\r\n2,408\r\n\r\n\r\n49.6%\r\n\r\n\r\nxR is robust\r\nTo illustrate how xR is more robust against judging blunders than win percent, let’s consider Volkanovski vs Holloway 2 from UFC 251. According to many in the MMA community, Volkanovski’s split decision win was controversial. In fact, 67% of the media members whose scores were reported on MMADecisions had Holloway winning the decision.\r\nTable 6 below shows xR by round for this fight. We see that the machine learning algorithm used to generate xR agrees with the judges that Volkanovski won the fight. Our purpose here is not to argue whether xR is correct or incorrect. Instead, I argue that either way, whether xR and the judges correctly scored the fight or not, the xR% metric does a better job than win percent at accurately representing each fighter’s performance in this fight.\r\n\r\n\r\nTable 6: xR of Volkanovski vs Holloway 2\r\n\r\n\r\nRound\r\n\r\n\r\nVolkanovski xR\r\n\r\n\r\nHolloway xR\r\n\r\n\r\n1\r\n\r\n\r\n0.184\r\n\r\n\r\n0.816\r\n\r\n\r\n2\r\n\r\n\r\n0.300\r\n\r\n\r\n0.700\r\n\r\n\r\n3\r\n\r\n\r\n0.967\r\n\r\n\r\n0.033\r\n\r\n\r\n4\r\n\r\n\r\n0.922\r\n\r\n\r\n0.078\r\n\r\n\r\n5\r\n\r\n\r\n0.974\r\n\r\n\r\n0.026\r\n\r\n\r\nTable 7 below shows the xR and xR% earned by each fighter for the fight. With respect to the official judging of this fight, there are two possible scenarios - either (a) the judges scored the fight correctly and Volkanovski deserved to win, or (b) the judges scored the fight incorrectly and Holloway deserved to win. Let’s examine each scenario in turn.\r\nIf the judges scored the fight correctly and Volkanovski deserved to win, then the xR% metric correctly awarded the majority of the xR available for the fight to Volkanovski. However, since this fight was close and since seemingly the majority of the MMA community had Holloway winning, it seems safe to say that a metric like win percent that leaves Holloway with nothing for his efforts is not representative of what occurred in the octagon. Instead, with xR%, Holloway earns xR equal to the amount of rounds he could have expected to win, on average, given his performance. Hence, in this case, xR% correctly scored the fight and more appropriately rewarded each fighter for his efforts.\r\nAlternatively, if the judges scored the fight incorrectly and Holloway deserved to win, then the xR% metric also incorrectly assigned xR to each fighter (since Volkanovski earned more xR for the fight). In this instance, Holloway unjustly takes a loss and his win percent suffers. If this had been a fight early in his career, Holloway’s win percent could have decreased significantly due to a mistake by the judges. However, even though xR is assigned poorly under this scenario, Holloway still receives around one-third of the available xR for the fight, which mitigates the hit to his career xR%. Therefore, even though both the judges and the underlying xR model incorrectly scored the fight, xR% at least provides Holloway with some credit.\r\nWe see that in either scenario xR% is both more informative (which we also discussed in a prior section) and more robust to judging blunders than win percent.\r\n\r\n\r\nTable 7: Total xR and xR%\r\n\r\n\r\nFighter\r\n\r\n\r\nxR\r\n\r\n\r\nxR%\r\n\r\n\r\nAlexander Volkanovski\r\n\r\n\r\n3.35\r\n\r\n\r\n66.9%\r\n\r\n\r\nMax Holloway\r\n\r\n\r\n1.65\r\n\r\n\r\n33.1%\r\n\r\n\r\nNote: \r\n\r\n\r\n -This table presents xR and xR% at the fight level.\r\n\r\n\r\nFinally, while this does not necessarily fit into the argument on the robustness of xR% as metric, I wanted to comment on the xR distribution in this example. The xR for round 3 went almost entirely to Volkanovski, yet I believe it is safe to say that round 3 was particularly close in the eyes of all viewers. As one of those viewers, I personally disagree with the distribution of xR here. However, I went back and checked out the official statistics for each round of this fight, and Volkanovski had a clear edge in round 3 on paper. This illustrates a limitation of xR: sometimes statistics do no tell the whole story. If you look at the official statistics for round 3, you should clearly see why most of the xR was given to Volkanovski. When the statistics are misleading, like in round 3 of this fight, xR may sometimes struggle to properly reflect reality. Nevertheless, while xR is not a perfect metric, I would argue that the judges are not perfect either. Both are wrong at times, but as I argued in this section, xR% is closer to the truth than the judges when it is wrong since it essentially awards partial credit to each fighter.\r\nxR is stable\r\nWhen I discuss a fighter evaluation metric’s stability, I am really referring to the degree to which the metric can swing on a fight-to-fight basis. Stability is important because a fighter evaluation metric should represent the quality of a fighter and then only improve or degrade as quickly as the fighter it is measuring improves or degrades. Fighters can have a bad fight, so we do not want a metric to overreact to a single performance - that would make the metric unstable.\r\nTo defend the claim that xR% is a more stable metric than win percent, I will first use a conceptual argument and then provide a mathematical argument.\r\nFirst, sample size is a particularly troubling issue in MMA, and small samples cause instability. Win percent utilizes each fight once, and as a result, it can be an unstable metric for fighters that do not have many fights. Judging errors, for example, can cause large, unjust deviations in a fighter’s win percent during the early part of his or her career. Hence, intuitively, we see that only drawing from a handful of fight outcomes coupled with the judging volatility ingrained in those outcomes makes win percent a relatively unstable metric, especially early in a fighter’s career.\r\nThe xR% metric, on the other hand, is computed using each round as an observation. Thus, after only 4-5 fights, a fighter will generally have fought 10 or more rounds. Utilizing these additional observations from each fight allows xR% to essentially observe each fighter’s dominance (or lack thereof) in the octagon more often than win percent, which only considers each fight once. The metric generated from more observations should vary less over time because the stability of the metrics under consideration is generally correlated with sample size. Therefore, conceptually, we can see how xR% should be able to produce a more stable measure of a fighter’s dominance in fewer fights than win percent.\r\nIf the conceptual argument has not convinced you, let’s look at the degree to which these metrics actually change over a fighter’s career. This argument is a bit technical and in the weeds, so feel free to skip it if it does not interest you.\r\nUsing every UFC fight in 2011-2020, we compute the standard deviation of the change in win percent and xR% from each fighter’s 1st-2nd UFC fight, and then we plot that point on the figure below corresponding to a value of 2 on the horizontal axis. Then, we take the difference in win percent and xR% from each fighter’s 2nd-3rd UFC fight, compute the standard deviation of those differences, and plot that point along the horizontal axis at a value of 3. We continue this process up to the 10th fight of each fighter’s career (among those who have fought that many times).\r\nThe lines on the figure below essentially measure the magnitude of the variation in each metric (along the vertical axis) as the number of fights used to compute each metric increases (along the horizontal axis). Smaller values on the vertical axis represent an increase in stability. Eventually both metrics will stabilize. That is, after many fights, the win percent, for example, will not change much whether a fighter wins or loses. Thus, we are more concerned with the stability of the metrics after the first few fights of a fighter’s career.\r\nWhile the actual values on the vertical axis do not need to be interpreted, what is important is how the two lines relate to one another. We see that the xR% line is always below that of win percent (especially after only a few fights), which means that the fight-by-fight change in xR% is generally less than that of win percent. Hence, xR% is mathematically the more stable metric, which aligns with the conceptual argument provided above.\r\n\r\n\r\n\r\nLimitations of xR\r\nWhile I have done my best to show the value of xR and xR% as fighter evaluation metrics, especially compared to convention metrics like win percent and finish percent, xR is far from perfect.\r\nFirst, xR does not account for the quality of an opponent. Therefore, it rewards high-quality fighters who resist the urge to climb the rankings quickly and instead dominate many unranked opponents.\r\nFurther, xR is computed using an imperfect machine learning algorithm that is developed using imperfect official UFC statistics and imperfect judging decisions. All machine learning models make errors. This model struggles the most when a fighter outperforms his or her opponent in the major statistical categories tracked but ends up taking more damage throughout the fight. Also, the official UFC statistics can be misleading, or even incorrect, at times, and lastly, the judges do make mistakes. Fortunately, the model still performs well even with all of these issues.\r\nExtensions of xR\r\nWhile I believe xR in its current state is incredibly valuable, I think there are a number of ways in which it can be improved or extended.\r\nAn opponent-adjusted xR that properly accounts for the quality of the opponent should noticeably improve the metric. If done correctly, a ranking system based on opponent-adjusted xR% could be useful.\r\nPerhaps most importantly, xR could be extended to other promotions if the round-level statistics and judging decisions were tracked and made publicly available. I believe this would greatly improve the value of xR and xR% in terms of both their informational and predictive value. Accounting for each fighter’s entire professional MMA career would, at the very least, increase the sample size and lead to better prospect evaluation and identification.\r\nConclusion\r\nQuantitative MMA analysis is challenging. Conventional fighter evaluation metrics like win percent and finish percent are easy to understand but leave a lot to be desired in terms of value.\r\nWhile certainly not perfect, xR and xR% provide noticeable improvements over these conventional metrics while not compromising on perhaps the most important aspect of an advanced metric: interpretability.\r\nThe figure below shows the xR% of current the top 5 men’s UFC pound-for-pound fighters. It is my hope that, after reading this post, everyone is able to fully understand what the lines on this figure represent.\r\n\r\n\r\n\r\nAs fighter evaluation metrics, xR and xR% are interpretable, informative, predictive, robust, and stable - which I believe makes them valuable to the entire MMA community.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-03-02-introducing-expected-rounds-xr/introducing-expected-rounds-xr_files/figure-html5/unnamed-chunk-3-1.png",
    "last_modified": "2021-03-03T01:19:42-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-02-25-extending-judgeai/",
    "title": "Extending JudgeAI",
    "description": "Aggregating JudgeAI's round score predictions to generate final scorecard probability distributions - with a case study on the judging decisions made during the main event of UFC 247: Jones vs Reyes",
    "author": [
      {
        "name": "Nate Latshaw",
        "url": {}
      }
    ],
    "date": "2021-02-25",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nCase study: Jon Jones vs Dominick Reyes\r\nRound 1\r\nRound 2\r\nRound 3\r\nRound 4\r\nRound 5\r\n\r\nMethodology: computing final scorecard probabilities\r\nJones vs Reyes final scorecard\r\nConclusion\r\n\r\nIntroduction\r\nIn my previous blog post, I introduced JudgeAI, a machine learning algorithm that uses round-level statistics to predict judges’ scores by round in the UFC. That post illustrated in detail how JudgeAI was built and how it performs across time. Overall, the model provides well-calibrated round win probabilities and is able to predict round scores with high accuracy. I strongly suggest reading that post if you are interested in understanding the methodological details of JudgeAI. Alternatively, if you’re interested in a quicker summary of the details of an earlier version of the model, you can check out my posts on Reddit and Twitter - those social media posts combine the information presented in this blog post and my previous post. This post largely assumes you either understand the technical details of JudgeAI or do not care about such details - either is perfectly fine.\r\nThis post seeks to extend JudgeAI by leveraging its round score probabilities to produce a probability distribution of all possible final scores. I hope audiences of all types find this post approachable. We explore the methodology by taking a look at the Jon Jones vs Dominick Reyes fight from UFC 247 on February 8, 2020, which was a unanimous, but controversial, decision by the judges. I also include a brief methodology section for those interested in how the round score probabilities are aggregated to produce final scorecard predictions.\r\nAs we will see, using JudgeAI’s round score probabilities to generate a distribution of final scores is a powerful way to utilize the underlying uncertainty in the round-level scoring, and then propagate that uncertainty across rounds, to understand how likely or unlikely each possible final score is. It also allows us to move away from thinking about discrete scores and move towards thinking probabilistically about judging decisions.\r\nCase study: Jon Jones vs Dominick Reyes\r\nRound 1\r\nThe figure below shows a number of statistics from the first round of Jones vs Reyes. Note that JudgeAI includes many more features than those shown here. The figure also displays the score given by each judge, the score given by JudgeAI, and JudgeAI’s probability of each score in 10-9, 10-8, 9-10, and 8-10.\r\nWe see that Reyes landed more significant strikes and only absorbed a single strike to the head. All 3 judges and JudgeAI scored this round 9-10 in favor of Reyes. Also, JudgeAI shows high confidence in its predicted score by placing an 81% probability on the majority of judges giving that score.\r\n\r\n\r\n\r\nRound 2\r\nThe figure below shows round 2. We see that Reyes landed 50% more significant strikes than Jones, and he landed more strikes to each of the head, body, and legs. JudgeAI again scored this 9-10 to Reyes. However, 2 of the 3 judges scored the round 10-9 to Jones.\r\nIt is important to note here that JudgeAI is not perfect. The model identifies broad trends in the relationship between round-level statistics and judges’ scores. Here the model is essentially saying that rounds with these striking differentials (plus all other statistics considered but not shown) go to the fighter who landed more strikes, which is Reyes here, around 3 out of every 4 times. While JudgeAI placed a high probability on Reyes winning this round, we cannot say for sure that 2 of the judges got this round wrong. Though striking differentials often correlate with damage dealt, for example, the model does not perfectly account for this. It is possible that Jones dealt more damage even though he landed fewer strikes.\r\nFinally, notice that JudgeAI was less certain about this 9-10 score than in the previous round. There is uncertainty in round-level scoring because judges are subjective and see different things in each round. This uncertainty propagates across rounds and can result in seemingly strange final scores. Hence, it is more important to focus on JudgeAI’s score probabilities than its predicted score of 9-10.\r\n\r\n\r\n\r\nRound 3\r\nRound 3 scores and statistics are displayed in the figure below. We see that Reyes again landed more significant strikes than Jones, and again, JudgeAI scored this round 9-10 to Reyes. However, 2 of the 3 judges scored this round 10-9 to Jones.\r\nOver rounds 2-3, either JudgeAI missed some important factor(s) in the fight, like damage dealt discrepancies, or it is safe to say that the judges were not doing Reyes any favors. The judges were split on the last 2 rounds, which suggests these rounds were tight, even though Reyes had the striking advantage on paper in both rounds.\r\n\r\n\r\n\r\nRound 4\r\nThe figure below shows round 4. We see that Jones landed more strikes than Reyes overall and to each of the head, body and legs. In addition, Jones landed the only takedown of the round and accumulated nearly 1 minute of control time. JudgeAI scored this round 10-9 to Jones with a very high probability, and all 3 judges agreed.\r\n\r\n\r\n\r\nRound 5\r\nThe final round is displayed below. Jones landed more significant strikes than Reyes and secured a takedown with around 30 seconds of control time. As in the last round, JudgeAI scored this round 10-9 to Jones with a high probability, and all 3 judges agreed.\r\n\r\n\r\n\r\nMethodology: computing final scorecard probabilities\r\nThis section provides a quick overview of the methodological details involved in computing the forthcoming final score probabilities. If that is not something that interests you, feel free to skip to the next section.\r\nRecall that our goal is to utilize JudgeAI’s round score probabilities to produce a probability distribution of all possible final scores. Such a distribution will provide more information than a discrete final score, like 48-47. Instead, the distribution will show how likely or unlikely each final score is after accounting for the uncertainty in round scoring that propagates across rounds.\r\nSince JudgeAI returns predicted probabilities for each score in 10-9, 10-8, 9-10, and 8-10, mathematically deriving the probability of each possible final score after 3 or 5 rounds is cumbersome. Hence, we instead use a Monte Carlo method to numerically compute final scorecard probabilities. That is, we essentially simulate the scoring of each round many times using JudgeAI’s round score probabilities and then see what proportion of simulated fights had each final score.\r\nThe computational algorithm employed is below.\r\nDraw 1 sample score for each round using JudgeAI’s corresponding round score probabilities. That is, for each round, draw a sample score from the possible scores 10-9, 10-8, 9-10, and 8-10 where the probability of drawing each possible score is set to the corresponding round score probability provided by JudgeAI.\r\nAdd each fighter’s sample scores together across rounds to generate the sample final score for the fight.\r\nRepeat the 2 steps above 100,000 times. This yields 100,000 final score samples.\r\nCompute final scorecard probabilities by dividing the number of times each final score appears in the samples by 100,000.\r\nJones vs Reyes final scorecard\r\nThe figure below shows the final scorecard for the fight and, according to JudgeAI coupled with the Monte Carlo method outlined above, the probability of each possible final score. We see that all 3 judges had Jones winning. However, if we add up JudgeAI’s predicted scores by round, we find that JudgeAI scored the fight 47-48 in favor of Reyes. Without properly aggregating JudgeAI’s round score probabilities, our analysis would end here, but fortunately, we recover a probability distribution of final scores that enables much more in-depth analysis.\r\nUsing the aforementioned algorithm to aggregate round score probabilities, we see that the most likely final score of 47-48 in favor of Reyes is expected to occur with a 43% probability. In other words, JudgeAI predicts that over many fights with the exact same round-level statistics as this fight, Reyes would win the decision 47-48 around 43% of the time.\r\nFurther, Reyes’ win probability (computed by adding up the appropriate final score probabilities) was 55%. Again, this means that over many fights with identical round-level statistics, JudgeAI predicts that Reyes would win via decision more often than not.\r\n\r\n\r\n\r\nEven though JudgeAI has Reyes winning this fight, notice that the win probability was barely over 50%. According to JudgeAI, the two most dominant rounds were 4 and 5, both of which went to Jones. This means that JudgeAI was more certain that the judges would also give these rounds to Jones, which turned out to be true as Jones won those rounds 10-9 on every scorecard. Since rounds are scored independently, once a fighter in a 5 round fight secures 2 dominant rounds, the math begins moving in that fighter’s direction. As we saw, JudgeAI had Reyes winning the other 3 rounds, which should be enough to win the decision. However, since Reyes’ round wins (according to JudgeAI) were less dominant, it was more likely that some judges would award some of those rounds to Jones, which is also what we saw.\r\nThis is the difference between using JudgeAI to score rounds probabilistically vs keeping track of one’s own personal round scores at home. The latter can lead to confusion or anger when comparing one’s own final score to that of the judges, while the former is more likely to help us understand how likely or unlikely a particular judge’s final score was. In this case, according to JudgeAI, two judges scoring the fight 48-47 to Jones was not terribly egregious, but the 49-46 score to Jones was relatively unlikely.\r\nIn the end, after accounting for the round-level scoring uncertainty, JudgeAI had Reyes winning with a 55% probability, which is quite low coming from a model that had Reyes winning 3 rounds. In this case, the uncertainty captured by JudgeAI lowered Reyes’ win probability from what we might have expected and happened to coincide with Jones winning the fight on each judge’s scorecard. Though JudgeAI still disagrees with the judges on the winner of the fight, the model only awarded Reyes a 55% win probability, which makes this fight a toss up.\r\nWhile the judges all agreed that Jones won the fight and JudgeAI had the fight as a toss up, the community seems to feel much more strongly that Reyes won. According to MMADecisions, which posts the official scorecards along with scores provided by members of the media and by fans, 14 of the 21 media members scored the fight 47-48 in favor of Reyes. The other 7 members of the media scored it 48-47 to Jones. In addition, as of the writing of this post, 77% of the fans who submitted scores had Reyes winning, the majority of which scored it 47-48 to Reyes. The scores provided by the community align with the two most likely final scores according to JudgeAI, but the share of media members and fans awarding the fight to Reyes is much higher than JudgeAI’s win probability for Reyes. Thus, the actual final scorecard submitted by the judges was generally much more surprising to media members and fans than it was to JudgeAI, which is likely due to the probabilistic decision-making of JudgeAI that is typically challenging for humans, and especially passionate fans, to replicate on their own.\r\nConclusion\r\nThe purpose of this post was not to argue that Reyes should have won the Lightweight title against Jones at UFC 247. Instead, this post serves to illustrate how the round score probabilities provided by JudgeAI can be aggregated to produce a probability distribution of final scores that is both unique and insightful.\r\nWe saw how using JudgeAI’s discrete round scores to score the fight resulted in a final score that did not match any of the judges on the final scorecard. However, leveraging JudgeAI’s round score probabilities allowed us to think probabilistically about how likely each final score might be. That is, we saw that Jones won the 2 most dominant rounds and thus only needed to win 1 of the 3 more competitive rounds on the judges’ scorecard. Hence, even though JudgeAI had Reyes winning the 3 more closely contested rounds, it only gave Reyes a 55% chance of winning the decision because of all the uncertainty in how judges were likely to score those 3 rounds. Media members and fans had Reyes winning at significantly higher rates than JudgeAI. While the resulting frustration among members of the media and fans may or may not be justified, I think that scoring a fight probabilistically with JudgeAI provides the community with valuable insights that are tough to get anywhere else.\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-02-25-extending-judgeai/extending-judgeai_files/figure-html5/unnamed-chunk-7-1.png",
    "last_modified": "2021-03-01T23:54:30-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  },
  {
    "path": "posts/2021-02-19-introducing-judgeai/",
    "title": "Introducing JudgeAI",
    "description": "A machine learning algorithm that predicts judges' scores by round in the UFC",
    "author": [
      {
        "name": "Nate Latshaw",
        "url": {}
      }
    ],
    "date": "2021-02-19",
    "categories": [],
    "contents": "\r\n\r\nContents\r\nIntroduction\r\nUFC data exploration\r\nBuilding JudgeAI\r\nEvaluating JudgeAI\r\nLimitations of JudgeAI\r\nExtending JudgeAI\r\n\r\nIntroduction\r\nFights in the Ultimate Fighting Championship (UFC) consist of 3 or 5 rounds, each of which lasts 5 minutes in duration. At any point in any round, the fight may end via knockout or submission. Otherwise, the winner of the fight is determined by the judges at the end of the final round. Each round is scored independently by 3 judges based on effective striking, effective grappling, octagon control, aggressiveness, and effective defense - in that order. Each judge awards 10 points to the winner of each round and 9 or fewer points to the loser (with some incredibly rare exceptions). Then, after the final round, each judge’s scores are added across rounds to arrive at the final scorecard. The fighter with more points for the majority of final scores is the winner of the fight.\r\nJudging decisions can be controversial. It’s often unclear how a particular judge came up with a certain seemingly unlikely score. Enter JudgeAI, a machine learning model that predicts round scores. If successful, JudgeAI will identify trends in the relationship between striking/grappling statistics and round scores given by the judges in order to quantify how likely or unlikely each possible score is for a round with a given set of statistics. While the publicly available statistics are far from a perfect measure of what the judges can see with their eyes throughout each round, it is my hope that these statistics are enough to proxy for the criteria judges use to score rounds such that JudgeAI need not watch a fight in order to accurately predict round scores.\r\nThe purpose of this post is twofold:\r\nCreate a machine learning algorithm, JudgeAI, that utilizes publicly available round-level statistics and judging decisions to predict round scores.\r\nDevelop a methodologically sound framework to properly illustrate how JudgeAI would have performed had it been implemented in the past in order to provide a valid measure of how well the model will perform in the future.\r\nOne final note before we get started: this post is primarily methodological in nature, which is admittedly off-putting to some. This post serves to illustrate what I did, how I did it, and how JudgeAI performs. I plan to use this post and the methodology described herein as a foundation for a number of derivative results and metrics that are hopefully much more accessible to those who enjoy the UFC but are not interested in these methodological details. It is my hope that this post will be a comprehensive reference for anyone interested in what’s happening with JudgeAI under the hood.\r\nUFC data exploration\r\nAccording to official UFC statistics, there were 4,399 fights in the UFC between 2011-2020, 48.3% of which resulted in a winner being declared by the judges’ scorecard. The figure below shows how UFC fights ended over this period. This post will focus on split and unanimous decisions only. A split decision occurs when the 3 judges do not all agree on which fighter won the fight, while a unanimous decision occurs when all 3 judges have the same winner on the final scorecard. Fortunately, the figure below shows that the number of split decisions is not noticeably rising over the past few years. Instead, if anything, judges are agreeing with each other at higher rates at the end of the decade, as measured by the proportion of decisions that are unanimous.\r\n\r\n\r\n\r\nUsing data from http://www.mmadecisions.com/, we explore how judges score fights by round. However, we first have to combine the judging data with the official UFC statistics data. As a result, we lose some fights. First, we drop all fights that do not end in a decision by the judges since scorecards are not publicly reported for any of the rounds in these fights. Then, we drop rounds where judging data was otherwise not available or where judges gave scores other than 10-8, 10-9, 9-10, or 8-10 since these potentially indicate a penalty where a point was deducted from one of the fighters (or other rare edge cases). By the end, of the 2,125 UFC fights between 2011-2020 where a winner was declared by the judges, 1,670 fights (containing 5,238 rounds) are successfully merged with the judging decisions data and retained for analysis. Unless otherwise stated, all subsequent counts and statistics refer to this set of fights, which comprises 78.6% of fights in which the judges selected a winner and 38.0% of all UFC fights between 2011-2020.\r\nIn order to predict round scores, we need to determine the “ground truth” score for each round. This is an inherently impossible task because if we had the ground truth then we would not need judges. Hence, we consider the “true” score of the round to be the score given by the majority of judges (i.e. at least 2 out of the 3 judges). Of the 5,238 rounds under consideration, all 3 judges provided the same score for 76.9%, or 4,029 rounds.\r\nIn the UFC, fighters are assigned to either the red corner or the blue corner. For title fights, the defending champion is always the red corner and the challenger is always the blue corner. For all other fights, the reasoning behind the corner assignments is not quite clear (at least not to me), but the red corner generally appears to be the more well-known and/or more experienced fighter. The figure below shows how rounds were scored between 2011-2020 (using the “true” round score), where the reported scores follow the convention: Red Corner Score - Blue Corner Score.\r\nWe see in the figure that red corners win more often than blue corners in each year. Over the entire period, the red corner won 57.6% of all rounds considered. Also, notice that 10-8 and 8-10 rounds are incredibly rare, comprising only 3.3% of all rounds considered.\r\n\r\n\r\n\r\n\r\n\r\n\r\nRecall that our goal is to develop a machine learning algorithm that predicts judges’ scores using the statistics accumulated in each round. However, before we do that, we first consider a simple, baseline decision rule that predicts round winners to which we can compare our eventual model’s performance. That is, the baseline decision rule predicts that whichever fighter landed more significant strikes in a round is the winner. Among rounds in which each fighter landed the same number of significant strikes, the fighter who landed more total strikes is predicted to be the winner. Finally, among the rounds remaining where each fighter landed the same number of significant and total strikes (only 0.9% of all rounds considered), the red corner is predicted to be the winner.\r\nTable 1 below shows how well our baseline decision rule is able to predict round winners across time. We see that the baseline rule performs relatively well in each year, which makes sense since the baseline only considers striking and since effective striking is the metric given the highest priority in the judges’ decision making. Of all rounds considered, the baseline rule correctly predicts the winner 77.8% of the time.\r\n\r\n\r\nTable 1: Baseline Round Winner Accuracy by Year\r\n\r\n\r\nYear\r\n\r\n\r\nNumber of Rounds\r\n\r\n\r\nBaseline Round Winner Accuracy\r\n\r\n\r\n2011\r\n\r\n\r\n237\r\n\r\n\r\n79.3%\r\n\r\n\r\n2012\r\n\r\n\r\n353\r\n\r\n\r\n80.5%\r\n\r\n\r\n2013\r\n\r\n\r\n348\r\n\r\n\r\n74.7%\r\n\r\n\r\n2014\r\n\r\n\r\n533\r\n\r\n\r\n76.9%\r\n\r\n\r\n2015\r\n\r\n\r\n604\r\n\r\n\r\n78.5%\r\n\r\n\r\n2016\r\n\r\n\r\n584\r\n\r\n\r\n75.0%\r\n\r\n\r\n2017\r\n\r\n\r\n562\r\n\r\n\r\n78.5%\r\n\r\n\r\n2018\r\n\r\n\r\n556\r\n\r\n\r\n79.1%\r\n\r\n\r\n2019\r\n\r\n\r\n766\r\n\r\n\r\n77.3%\r\n\r\n\r\n2020\r\n\r\n\r\n695\r\n\r\n\r\n78.8%\r\n\r\n\r\nNote: \r\n\r\n\r\n -Baseline decision rule predicts the winner as the fighter who landed more significant strikes. Ties go to whoever landed more total strikes, or the red corner if total strikes are also even.-“Round Winner Accuracy” is defined as the share of rounds in which the predicted round winner matches the winner declared by the majority of judges.\r\n\r\n\r\nNow that we have established a baseline decision rule, we proceed with building the predictive model, JudgeAI. The baseline decision rule only considers strikes landed, while the actual model will consider many more features for each round. If the eventual predictive model is any good, it will predict round winners more successfully than this simple baseline rule.\r\nBuilding JudgeAI\r\nThe outcome of interest for JudgeAI is the score given by the majority of judges for each round. That is, the outcome will be one of 10-9, 10-8, 9-10, or 8-10, and again, the scores follow the convention: Red Corner Score - Blue Corner Score. JudgeAI will use the statistics accumulated by each fighter during each round to predict the outcome. The official UFC statistics provide striking and grappling statistics, to include total strikes landed and attempted, significant strikes landed and attempted, knockdowns, takedowns landed and attempted, submission attempts, reversals, and control time. In addition, significant strikes are broken down into strikes to the head, body, or legs; and strikes at distance, in the clinch, or on the ground. Using strikes and takedowns landed and attempted, we also compute striking and takedown accuracy, respectively. Finally, rather than including each fighter’s round-level statistics separately in the model, we instead include the difference by taking the red corner’s statistic minus that of the blue corner, for each statistic included. In total, there are 31 features included in the model, all of which are statistical differences.\r\nPut more simply, each observation in the model is a single round where the outcome is the score given by the majority of judges, and the features used to predict each majority score are the differences between each fighter’s accumulated statistics. For example, one feature in the model is the difference in total strikes landed for each round, which is computed by subtracting the number of total strikes landed by the blue corner from the number of total strikes landed by the red corner.\r\nSince we are predicting scores over time and since judging and fighter tendencies can change over time, we employ time series cross validation to train and evaluate our predictions. That is, for each month in the period, beginning with January 2012, we train the model using data from all prior months in the period and then make predictions on the single month under consideration. Table 2 below illustrates the time series cross validation strategy where a series of models is trained, each of which predicts scores for a single month of fights (“Evaluation Month” from the table) using all prior data in the period (“Training Months” from the table). Using time series cross validation, we obtain predictions for every month in the “Evaluation Month” column of the table below.\r\n\r\n\r\nTable 2: Time Series Cross Validation Strategy\r\n\r\n\r\nTraining Months\r\n\r\n\r\nEvaluation Month\r\n\r\n\r\nJanuary 2011 - December 2011\r\n\r\n\r\nJanuary 2012\r\n\r\n\r\nJanuary 2011 - January 2012\r\n\r\n\r\nFebruary 2012\r\n\r\n\r\nJanuary 2011 - February 2012\r\n\r\n\r\nMarch 2012\r\n\r\n\r\n…\r\n\r\n\r\n…\r\n\r\n\r\nJanuary 2011 - October 2020\r\n\r\n\r\nNovember 2020\r\n\r\n\r\nJanuary 2011 - November 2020\r\n\r\n\r\nDecember 2020\r\n\r\n\r\nNote: \r\n\r\n\r\n -Data in the “Training Months” are used to build each model. Predictions are then made on data in the “Evaluation Month”.\r\n\r\n\r\nThis modeling strategy contains 3 key advantages over a more simple approach of splitting the data into a training and test set - these advantages are:\r\nAll predictions are made on fights unseen by the model through which predictions are made (i.e. we use out-of-sample predictions only).\r\nWe recover predictions for the entire period, except for fights in 2011. Since 2011 is the first year we have data, we only use it for training.\r\nWe are not “cheating” by using a model trained on fights that come after the fights on which we are predicting. This more accurately simulates how successful JudgeAI would have performed had it been implemented in the past, and it gives us a better sense of how well JudgeAI will perform going forward.\r\nThese 3 advantages are significant and essential to the validity of the model evaluation section. Without (1), we would be making predictions on rounds that the model has already seen, which would incorrectly inflate the performance. Further, advantage (2) is important because it provides us with a large sample by which to evaluate model performance, which gives us a more robust estimate of future performance. Finally, without (3), the model would not accurately convey historical performance. For example, if the model is trying to predict round scores for fights in 2014 but is trained using rounds from 2018, the resulting performance would not be realistic because the model is using fights that have not happened yet to make predictions.\r\nThe algorithm I’ve chosen to use is random forests since it quickly and efficiently builds an ensemble of decision trees to make predictions without overfitting. Also, decision trees are able to capture complex interactions between features, which means we do not have to specify which combinations of features should be considered in conjunction with one another; instead, the algorithm will detect these relationship automatically by design. Each algorithm in the time series cross validation is trained using 500 decision trees to grow a probability forest. Hence, for each round, the algorithm provides a predicted probability of each possible score out of the scores 10-9, 10-8, 9-10, and 8-10.\r\n\r\n\r\n\r\nEvaluating JudgeAI\r\nAfter performing time series cross validation, we now have a predicted probability of each possible score for each round in our sample (again, excluding fights in 2011). After aggregating these round score probabilities up to round win probabilities, the figure below shows how well these round win probabilities are calibrated. If JudgeAI yields well-calibrated probabilities, then we should observe, for example, the red corner winning approximately 60% of rounds in which JudgeAI gives the red corner around a 60% probability of winning. In other words, the figure below checks whether the round win probabilities mean what we want them to mean. Each point represents a group of rounds with both (a) red corner predicted win probabilities centered around the corresponding points on the horizontal axis, and (b) observed red corner win shares equal to the corresponding points along the vertical axis. Points that hug the displayed 45 degree line are considered well calibrated. Since this is real-world data, perfect calibration is not expected, and overall, this figure is quite promising. In aggregate, JudgeAI’s predicted round win probabilities do more or less reflect the share of rounds won historically.\r\n\r\n\r\n\r\nUsing the predicted probabilities for each possible score, we define the predicted score as the score with the highest predicted probability from the model. We then compute the scoring accuracy of the model by determining the number of rounds in which the predicted score matches the score given by the majority of the judges and then dividing by the total number of rounds. That is,\r\n\\(\\text{Scoring accuracy} = \\frac{\\text{# of rounds where predicted score = judges' majority score}}{\\text{total number of rounds}}\\).\r\nOver all fights considered between 2012-2020, the model’s scoring accuracy is 80.2%, which means that the model agrees with the majority of judges on the particular score in approximately 4 out of every 5 rounds.\r\nDiving deeper into performance metrics, the model predicts the same round winner as the majority of judges in 83.3% of rounds. An example of the difference between this measure and the scoring accuracy reported before would be a round where the model’s predicted score is 10-9, but the majority of judges score it 10-8. Both the model and the judges have the same round winner, but they disagree on the particular score of the round.\r\nWhile JudgeAI performs well based on how frequently it agrees with the majority of judges, it is also beneficial to see how often it agrees with any judge. If all 3 judges agree on a particular round score or round winner, it is much more likely that this score or winner is objectively correct. Hence, JudgeAI should very rarely give a predicted score or predicted round winner that disagrees with every judge. Fortunately, such occurrences are rare. The model’s predicted scores match at least 1 judge’s score in 90.8% of rounds. Likewise, the model’s predicted round winner matches that of at least 1 judge in 92.3% of rounds.\r\nFurther, the figure below displays the model’s performance by year and shows that performance is both strong and consistent across time. To the extent that judging biases or preferences change over time, the model adapts well without any egregious degradation. Similarly, as the sport of mixed martial arts (MMA) evolves over time, the judges may modify their internal interpretations of the scoring criteria in order to consistently and fairly score fights. Based on the consistency of the model’s performance over time, the evolution of the sport across the period does not appear to adversely impact the generalizability of the model.\r\n\r\n\r\n\r\nTable 3 below compares the model’s performance to the aforementioned baseline decision rule with respect to round winner accuracy. In each year considered, the model is more accurate at determining round winners, which is expected since it accounts for more than just strikes landed. Moreover, the model is significantly more valuable than the baseline because it makes predictions for each possible round score, instead of only the round winner, and it assigns a probability to each possible outcome, instead of just a binary prediction. Ultimately, the baseline decision rule is not a tough bar to clear, but it is nonetheless encouraging that our model is a drastic improvement over a hypothetical judge that only considers strikes landed and ignores all other aspects of the fight.\r\n\r\n\r\nTable 3: Comparing Round Winner Predictions by Year\r\n\r\n\r\nYear\r\n\r\n\r\nNumber of Rounds\r\n\r\n\r\nBaseline Round Winner Accuracy\r\n\r\n\r\nJudgeAI Round Winner Accuracy\r\n\r\n\r\n2012\r\n\r\n\r\n353\r\n\r\n\r\n80.5%\r\n\r\n\r\n83.0%\r\n\r\n\r\n2013\r\n\r\n\r\n348\r\n\r\n\r\n74.7%\r\n\r\n\r\n83.3%\r\n\r\n\r\n2014\r\n\r\n\r\n533\r\n\r\n\r\n76.9%\r\n\r\n\r\n84.2%\r\n\r\n\r\n2015\r\n\r\n\r\n604\r\n\r\n\r\n78.5%\r\n\r\n\r\n84.1%\r\n\r\n\r\n2016\r\n\r\n\r\n584\r\n\r\n\r\n75.0%\r\n\r\n\r\n81.3%\r\n\r\n\r\n2017\r\n\r\n\r\n562\r\n\r\n\r\n78.5%\r\n\r\n\r\n83.5%\r\n\r\n\r\n2018\r\n\r\n\r\n556\r\n\r\n\r\n79.1%\r\n\r\n\r\n84.5%\r\n\r\n\r\n2019\r\n\r\n\r\n766\r\n\r\n\r\n77.3%\r\n\r\n\r\n82.2%\r\n\r\n\r\n2020\r\n\r\n\r\n695\r\n\r\n\r\n78.8%\r\n\r\n\r\n83.7%\r\n\r\n\r\nNote: \r\n\r\n\r\n -“Round Winner Accuracy” is defined as the share of rounds in which the predicted round winner matches the winner declared by the majority of judges.\r\n\r\n\r\nFinally, to unpack the model a bit more and see which statistics it relies upon the most to score rounds, we use feature importance. Table 4 below displays the top 10 most important features in the model, where importance is essentially defined as how helpful the feature is in predicting the outcome. Again, when scoring a round, judges are supposed to consider effective striking, effective grappling, octagon control, aggressiveness, and effective defense - in that order. Examining the table below shows that JudgeAI appears to be capturing the exact same criteria in nearly the exact same order. This promising result suggests that both (a) judges generally follow the criteria with which they are provided, as expected, and (b) JudgeAI is able to use the round-level statistics to effectively capture this criteria when predicting round scores.\r\n\r\n\r\nTable 4: Top 10 Most Important Model Features\r\n\r\n\r\nRank\r\n\r\n\r\nFeature\r\n\r\n\r\nCorresponding Judging Criteria\r\n\r\n\r\n1\r\n\r\n\r\nDifference in significant strikes landed\r\n\r\n\r\nEffective striking\r\n\r\n\r\n2\r\n\r\n\r\nDifference in total strikes landed\r\n\r\n\r\nEffective striking\r\n\r\n\r\n3\r\n\r\n\r\nDifference in control time\r\n\r\n\r\nOctagon control, effective grappling\r\n\r\n\r\n4\r\n\r\n\r\nDifference in significant strikes landed to the head\r\n\r\n\r\nEffective striking\r\n\r\n\r\n5\r\n\r\n\r\nDifference in total strikes attempted\r\n\r\n\r\nAggressiveness\r\n\r\n\r\n6\r\n\r\n\r\nDifference in significant strikes attempted\r\n\r\n\r\nAggressiveness\r\n\r\n\r\n7\r\n\r\n\r\nDifference in significant strike accuracy\r\n\r\n\r\nEffective striking, effective defense\r\n\r\n\r\n8\r\n\r\n\r\nDifference in significant strike accuracy to the head\r\n\r\n\r\nEffective striking, effective defense\r\n\r\n\r\n9\r\n\r\n\r\nDifference in significant strikes attempted on the ground\r\n\r\n\r\nEffective grappling\r\n\r\n\r\n10\r\n\r\n\r\nDifference in total strike accuracy\r\n\r\n\r\nEffective striking, effective defense\r\n\r\n\r\nNote: \r\n\r\n\r\n -Feature importance is computed on a model including all rounds in the period, as opposed to using one of the models created via time series cross validation.-Differences are computed by subtracting each blue corner statistic from the corresponding red corner statistic.\r\n\r\n\r\nLimitations of JudgeAI\r\nI’d like to clearly state that JudgeAI is not perfect. I am not claiming that it is better than any particular judge, nor am I suggesting that it should replace judges in the UFC.\r\nWhile the consistently strong performance of JudgeAI over time is promising, this algorithm does have serious limitations. First and foremost, statistics do not perfectly convey damage dealt. Effective striking is the primary judging criteria, and even though accumulating many more significant strikes than one’s opponent does correlate with dealing more damage, just looking at statistical differences will not replace what we can see from watching a fight. This issue is especially problematic in rounds that are close statistically but not as close when you watch it because one fighter clearly lands harder blows.\r\nFurther, JudgeAI seeks to uncover longer-term trends in the relationship between round scores and the features included in the model. Therefore, JudgeAI uses these broader relationships to score every round no matter what, but in reality, many rounds include some sort of rare occurrence, like a devastating calf kick that leaves a fighter largely immobile, that can and perhaps should sway the judges but will go unnoticed by the model. Similarly, the model only sees the aggregate statistics for each round, so if a particular fighter starts slow in the first half but dominates the second half of a round, the judges might give this round to the strong finisher while the model might not.\r\nFinally, the vast majority of rounds are scored 10-9 for the winner. As a result, JudgeAI struggles to predict 10-8 rounds with a high probability, even when the striking statistics are wildly lopsided. There are methodological adjustments that could be made to increase the model’s precision in this regard, but I have not yet explored such changes.\r\nExtending JudgeAI\r\nThe most obvious extension of JudgeAI would be aggregating the round-level predictions to produce a distribution of potential final scores. Since JudgeAI produces round score probabilities instead of just round win probabilities, it is possible to use the model’s predictions to generate a complete probability distribution for every possible final score. This would allow us to account for the underlying uncertainty in the round-level scoring while identifying the most likely final score.\r\nWhile JudgeAI cannot be used to definitively say that a particular judge gave the wrong score for a particular round, it can be used to assess judges over a larger sample of fights. Since the model is calibrated to reflect the majority decision of judges and since it is largely successful in doing so over time, identifying any judges whose scores regularly deviate from JudgeAI’s scores over a large sample of fights could be fruitful.\r\nFinally and most importantly, I believe JudgeAI can be leveraged to create brand new advanced metrics for MMA. Baseball has expected runs that uses statistics from within an inning to essentially compute the number of runs a team would expect to score, on average, after generating those statistics. Likewise, soccer has expected goals that uses the probability of scoring on each shot a team takes over the course of a game to calculate the total number of goals a team would expect to score, on average, after taking shots from those locations. I believe JudgeAI’s predicted round win probabilities can be used to create expected rounds, a metric that measures the number of rounds fighters would expect to win, on average, after compiling their observed round-level statistics. If successful, this new metric can move the sport away from looking at win percents or finish percents and towards a more informative metric that describes how dominant each fighter is on a round-by-round basis.\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/2021-02-19-introducing-judgeai/introducing-judgeai_files/figure-html5/unnamed-chunk-6-1.png",
    "last_modified": "2021-03-01T23:33:14-05:00",
    "input_file": {},
    "preview_width": 1248,
    "preview_height": 768
  }
]
